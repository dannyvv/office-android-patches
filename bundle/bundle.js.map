{"version":3,"sources":["webpack:///webpack/bootstrap","webpack:///./src/logger.ts","webpack:///external \"fs-extra\"","webpack:///external \"path\"","webpack:///./src/patch_utils.ts","webpack:///./src/patch/assertNever.ts","webpack:///./src/fs_utils.ts","webpack:///external \"fs\"","webpack:///external \"child_process\"","webpack:///./src/patch/parse.ts","webpack:///./src/file_type_utils.ts","webpack:///./src/index.ts","webpack:///./src/diffRepos.ts","webpack:///external \"winston\"","webpack:///./src/patch/apply.ts","webpack:///./src/patch/reverse.ts","webpack:///./src/patch/read.ts","webpack:///external \"istextorbinary\"","webpack:///./src/file_compare.ts","webpack:///external \"crypto\"","webpack:///./src/git_utils.ts","webpack:///./src/patchRepo.ts","webpack:///./src/patchFile.ts","webpack:///./src/cli.ts","webpack:///external \"commander\""],"names":["installedModules","__webpack_require__","moduleId","exports","module","i","l","modules","call","m","c","d","name","getter","o","Object","defineProperty","enumerable","get","r","Symbol","toStringTag","value","t","mode","__esModule","ns","create","key","bind","n","object","property","prototype","hasOwnProperty","p","s","loggerSourcePath","__dirname","loggerParentDir","resolve","logDirBase","Date","now","getLogDirectoryDev","createLogger","level","defaultMeta","service","format","combine","timestamp","json","transports","Console","handleExceptions","errors","log","queryErrors","resultCallback","setLogFolder","logFolder","add","File","filename","dirname","exceptions","handle","error","prefix","message","message2","push","warn","info","verbose","require","path1","path1IsNew","path2","callback","errorcallback","diffExecutable","diffArgs","diff","spawn","stdout","on","data","stderr","code","targetPath","patchPath","patchExecutable","reverse","patchArgs","patch","toString","patchFilePath","targetFilePathOverride","readPatch","executeEffects","reversePatch","dryRun","e","x","Error","resolvePath","base","relative","isDirectory","path","lstatSync","isRegularFile","isFile","isSymlink","isSymbolicLink","ensureDirOfPathExists","filePath","dir","parse","ensureDirSync","basename","extname","absPath","basepath","relativefilepath","extension","relative_dir","absPath1","existsSync","absPath2","writeFileSync","traverseDirectory","rootAbsPath","relPath","callbackFile","callbackDirectory","blackListDirs","recursive","readdirSync","forEach","childpath","absChildPath","relChildPath","includes","startsWith","substr","relativePath","callbackOnHit","callbackOnMiss","removeSync","absSourecPath","absDestinationPath","copyFileSync","destBasepath","destRelativefilepath","sourcePath","destRelativeDir","destAbsDir","destAbsPath","parseHunkHeaderLine","headerLine","match","trim","original","start","Math","max","Number","length","patched","NON_EXECUTABLE_FILE_MODE","EXECUTABLE_FILE_MODE","hunkLinetypes","undefined","parsePatchLines","lines","supportLegacyDiffs","result","currentFilePatch","diffLineFromPath","diffLineToPath","oldMode","newMode","deletedFileMode","newFileMode","renameFrom","renameTo","beforeHash","afterHash","fromPath","toPath","hunks","state","currentHunk","currentHunkMutationPart","commitHunk","parts","commitFilePatch","line","slice","lineType","header","noNewlineAtEndOfFile","type","assertNever","hunk","verifyHunkIntegrity","interpretParsedPatchFile","files","file","destinationFilePath","parseFileMode","hash","parsedMode","parseInt","originalLength","patchedLength","split","pop","filepath","isTextSync","isBinarySync","initCli","process","exitCode","write","dirtyRepoAbsPath","baseRepoAbsPath","options","patchName","whitelistDirs","blacklistDirs","blacklistExts","gitExecutable","cleanupRepos","cleanupExistingPatches","patchStorePath","initDirectory","cleanRepoSync","baseFork","dirtyFork","dirtyRepoFileAbsPath","forkFileRelativePath","getRelativePath","fileNameExtension","getFileNameExtension","lookUpRelativePath","fbRepoFileAbsPath","callbackOnDiffCreated","writeFile","callbackOnError","callbackOnBinaryFilesCompare","same","copyFile2","callbackOnBinaryFilesCompareError","isFileBinary","compareFiles","diffFiles","isExecutable","fileMode","effects","eff","unlinkSync","moveSync","fileContents","join","effectiveTargetPath","readFileSync","statSync","fileLines","fuzzingOffset","modifications","evaluateHunk","abs","indexOf","diffOffset","modification","splice","index","numToDelete","linesToInsert","applyPatch","currentMode","console","chmodSync","trimRight","replace","contextIndex","part","originalLine","b","reverseHunk","tmp","reversePatchPart","map","parsePatchFile","exit","hash1","createHash","stream1","createReadStream","update","hash1Digest","digest","hash2","stream2","hash2Digest","gitClean","spawnSync","cwd","embeddedPatcher","applyPatchEmbedded","applyPatchTool","targetRepoAbsPath","patchNames","patchStore","patchFileAbsPath","patchFileRootAbsPath","patchFileRelativePath","hitPatchFileAbsPath","copyFileOverwrite","missedPatchFileAbsPath","copyFile","patchNameDirAbsPath","targetFileAbsPath","version","diffReposFunc","patchRepoFunc","patchFileFunc","onCompletionFunc","commaSeparatedList","dummyPrevious","command","description","option","action","dirtyRepo","baseRepo","cmdObject","targetRepo","targetFilePath","argv"],"mappings":"aACE,IAAIA,EAAmB,GAGvB,SAASC,EAAoBC,GAG5B,GAAGF,EAAiBE,GACnB,OAAOF,EAAiBE,GAAUC,QAGnC,IAAIC,EAASJ,EAAiBE,GAAY,CACzCG,EAAGH,EACHI,GAAG,EACHH,QAAS,IAUV,OANAI,EAAQL,GAAUM,KAAKJ,EAAOD,QAASC,EAAQA,EAAOD,QAASF,GAG/DG,EAAOE,GAAI,EAGJF,EAAOD,QAKfF,EAAoBQ,EAAIF,EAGxBN,EAAoBS,EAAIV,EAGxBC,EAAoBU,EAAI,SAASR,EAASS,EAAMC,GAC3CZ,EAAoBa,EAAEX,EAASS,IAClCG,OAAOC,eAAeb,EAASS,EAAM,CAAEK,YAAY,EAAMC,IAAKL,KAKhEZ,EAAoBkB,EAAI,SAAShB,GACX,oBAAXiB,QAA0BA,OAAOC,aAC1CN,OAAOC,eAAeb,EAASiB,OAAOC,YAAa,CAAEC,MAAO,WAE7DP,OAAOC,eAAeb,EAAS,aAAc,CAAEmB,OAAO,KAQvDrB,EAAoBsB,EAAI,SAASD,EAAOE,GAEvC,GADU,EAAPA,IAAUF,EAAQrB,EAAoBqB,IAC/B,EAAPE,EAAU,OAAOF,EACpB,GAAW,EAAPE,GAA8B,iBAAVF,GAAsBA,GAASA,EAAMG,WAAY,OAAOH,EAChF,IAAII,EAAKX,OAAOY,OAAO,MAGvB,GAFA1B,EAAoBkB,EAAEO,GACtBX,OAAOC,eAAeU,EAAI,UAAW,CAAET,YAAY,EAAMK,MAAOA,IACtD,EAAPE,GAA4B,iBAATF,EAAmB,IAAI,IAAIM,KAAON,EAAOrB,EAAoBU,EAAEe,EAAIE,EAAK,SAASA,GAAO,OAAON,EAAMM,IAAQC,KAAK,KAAMD,IAC9I,OAAOF,GAIRzB,EAAoB6B,EAAI,SAAS1B,GAChC,IAAIS,EAAST,GAAUA,EAAOqB,WAC7B,WAAwB,OAAOrB,EAAgB,SAC/C,WAA8B,OAAOA,GAEtC,OADAH,EAAoBU,EAAEE,EAAQ,IAAKA,GAC5BA,GAIRZ,EAAoBa,EAAI,SAASiB,EAAQC,GAAY,OAAOjB,OAAOkB,UAAUC,eAAe1B,KAAKuB,EAAQC,IAGzG/B,EAAoBkC,EAAI,GAIjBlC,EAAoBA,EAAoBmC,EAAI,I,oKClFrD,iBACA,UAG2B,MACzB,MAAMC,EAAmBC,UACnBC,EAAkB,UAAQC,QAAQH,EAAkB,MACpDI,EAAa,UAAQD,QAAQD,EAAiB,QAC7C,UAAQC,QAAQC,EAAY,GAAGC,KAAKC,UAGxBC,GAEN,UAAQC,aAAa,CAClCC,MAAO,UACPC,YAAa,CAACC,QAAS,gBACvBC,OAAQ,UAAQA,OAAOC,QACrB,UAAQD,OAAOE,YACf,UAAQF,OAAOG,QAEjBC,WAAY,CACV,IAAI,UAAQA,WAAWC,QAAQ,CAC7BC,kBAAkB,EAClBT,MAAO,aAqCb,MAAMU,EAAmB,GAwCzB,MAAMC,EAAM,CAACC,YA7Bb,SAAqBC,GA0BnBA,EAAeH,IAGSI,aAxE1B,SAAsBC,GAGpB,UAAQC,IACN,IAAI,UAAQT,WAAWU,KAAK,CAC1BC,SAAU,YACVlB,MAAO,QACPmB,QAASJ,KAGb,UAAQC,IACN,IAAI,UAAQT,WAAWU,KAAK,CAC1BC,SAAU,UACVC,QAASJ,KAGb,UAAQK,WAAWC,OACjB,IAAI,UAAQd,WAAWU,KAAK,CAC1BC,SAAU,iBACVC,QAASJ,MAqDyBO,MAvCxC,SAAeC,EAAgBC,GAC7B,MAAMC,EAAW,GAAGF,OAAYC,IAChCd,EAAOgB,KAAKD,GACZ,UAAQH,MAAMG,IAoC+BE,KAjC/C,SAAcJ,EAAgBC,GAC5B,UAAQG,KAAK,GAAGJ,OAAYC,MAgCuBI,KAhDrD,SAAcL,EAAgBC,GAC5B,UAAQI,KAAK,GAAGL,OAAYC,MA+C6BK,QA5C3D,SAAiBN,EAAgBC,GAC/B,UAAQK,QAAQ,GAAGN,OAAYC,OA4CzB,EAAAb,O,cCrGRrD,EAAOD,QAAUyE,QAAQ,a,cCAzBxE,EAAOD,QAAUyE,QAAQ,S,8ECAzB,aAEA,OAEA,QACA,QACA,QAUA,qBACEC,EACAC,EACAC,EACAC,EACAC,EACAC,GAEA,MAAMC,EAAW,CAACN,EAAOE,EAAO,MAC5BD,GAAYK,EAASX,KAAK,6BAE9B,MAAMY,EAAO,EAAAC,MAAMH,EAAgBC,GAEnCC,EAAKE,OAAOC,GAAG,OAASC,IACtBR,EAASQ,KAGXJ,EAAKK,OAAOF,GAAG,OAASC,IACtBP,EAAc,GAAGC,KAAkBC,0BAAiCK,OAGtEJ,EAAKG,GAAG,QAAUG,IAChB,EAAAjC,IAAIkB,QAAQ,QAAS,sCAAsCe,QAI/D,0BACEC,EACAC,EACAZ,EACAC,EACAY,EACAC,GAEA,MAAMC,EAAY,CAAC,KAAMH,EAAWD,EAAY,MAC5CG,GACFC,EAAUvB,KAAK,MAGjB,MAAMwB,EAAQ,EAAAX,MAAMQ,EAAiBE,GACrC,EAAAtC,IAAIiB,KACF,QACA,uDACEqB,EAAUE,YAGdD,EAAMT,GAAG,UAAYjB,IACnBU,EAAS,kBAAkBV,OAG7B0B,EAAMV,OAAOC,GAAG,OAASC,IACvBR,EAAS,iBAAiBQ,OAG5BQ,EAAMP,OAAOF,GAAG,OAASC,IACvBP,EACE,GAAGY,KAAmBE,0BAAkCP,OAI5DQ,EAAMT,GAAG,QAAUG,IACjB,EAAAjC,IAAIiB,KAAK,QAAS,wCAAwCgB,QAI9D,+BAAmC,cACjCQ,EAAa,uBACbC,EAAsB,QACtBL,IAMA,MAAME,EAAQ,EAAAI,UAAU,CAACF,kBACzB,IACE,EAAAG,eACEP,EAAU,EAAAQ,aAAaN,GAASA,EAChCG,EACA,CACEI,QAAQ,IAGZ,MAAOC,GACP,IACE,EAAAH,eACEP,EAAUE,EAAQ,EAAAM,aAAaN,GAC/BG,EACA,CACEI,QAAQ,IAGZ,MAAOC,GAEP,OADA,EAAA/C,IAAIW,MAAM,cAAe,0BAA0BoC,MAC5C,GAIX,OAAO,I,8EClHT,aACA,uBAA4BC,GAE1B,MADA,EAAAhD,IAAIW,MAAM,cAAe,sBAAwBqC,GAC3C,IAAIC,MAAM,sBAAwBD,K,kKCH1C,gBACA,UACA,UAEA,OAUA,SAAgBE,EAAYC,EAAcC,GACxC,OAAO,UAAQrE,QAAQoE,EAAMC,GAG/B,SAAgBC,EAAYC,GAC1B,IACE,OAAO,UAAGC,UAAUD,GAAMD,cAC1B,MAAON,GACP,EAAA/C,IAAIW,MAAM,iBAAkB,GAAG2C,MAASP,MAI5C,SAAgBS,EAAcF,GAC5B,IACE,OAAO,UAAGC,UAAUD,GAAMG,SAC1B,MAAOV,GACP,EAAA/C,IAAIW,MAAM,mBAAoB,GAAG2C,MAASP,MAI9C,SAAgBW,EAAUJ,GACxB,IACE,OAAO,UAAGC,UAAUD,GAAMK,iBAC1B,MAAOZ,GACP,EAAA/C,IAAIW,MAAM,eAAgB,GAAG2C,MAASP,MA+H1C,SAASa,EAAsBC,GAC7B,MAAMC,EAAM,UAAQC,MAAMF,GAAUC,IACpC,UAAIE,cAAcF,GAjKpB,oCAAyCR,GACvC,OAAO,UAAQW,SAASX,IAG1B,gCAAqCA,GACnC,OAAO,UAAQY,QAAQZ,IAGzB,gBAIA,gBAQA,kBAQA,cAQA,2BAAgCa,EAAiBhB,GAC/C,OAAO,UAAQC,SAASD,EAAMgB,IAIhC,qBACEC,EACAC,EACAtC,EACAuC,GAEA,IAEE,MAAMnH,EAAO,UAAQ8G,SAASI,GACxBE,EAAe,UAAQR,MAAMM,GAAkBP,IAG/CU,EAAW,UAAQzF,QAAQqF,EAAUG,GACtC,UAAGE,WAAWD,IACjB,UAAIR,cAAcQ,GAGpB,MAAME,EAAW,UAAQ3F,QACvByF,EACAF,EAAY,GAAGnH,KAAQmH,IAAcnH,GAGnC,UAAGsH,WAAWC,IAChB,EAAA1E,IAAIW,MACF,eACA,iDAAiD+D,KAIrD,UAAGC,cAAcD,EAAU3C,GAC3B,MAAOgB,GACP,EAAA/C,IAAIW,MACF,eACA,wBAAwByD,MAAaC,MAAqBtB,OAOhE,6BAAgB6B,EACdC,EACAC,EACAC,EACAC,EACAC,EAA0B,GAC1BC,GAAqB,GAErB,EAAAlF,IAAIkB,QAAQ,oBAAqB,YAAY2D,MAAgBC,KAC7D,MAAMxB,EAAOJ,EAAY2B,EAAaC,GACtC,GAAItB,EAAcF,GAChByB,EAAazB,EAAMuB,QACd,GAAIxB,EAAYC,GAAO,CACX,UAAG6B,YAAY7B,GACvB8B,QAASC,IAChB,MAAMC,EAAe,UAAQvG,QAAQuE,EAAM+B,GACrCE,EAAeT,EAAU,KAAOO,EAIpCJ,EAAcO,SACZD,EAAaE,WAAW,OACpBF,EAAaG,OAAO,GACpBH,GAGN,EAAAvF,IAAIkB,QACF,oBACA,YAAY2D,MAAgBU,2BAKhCP,EAAkBM,EAAcT,GAC5BK,GACFN,EACEC,EACAU,EACAR,EACAC,EACAC,EACAC,WAGGxB,EAAUJ,IACnB,EAAAtD,IAAIW,MACF,uBACA,uCAAuC2C,MAM7C,8BACEA,EACAqC,EACAC,EACAC,GAEA,MAAMP,EAAe,UAAQvG,QAAQuE,EAAMqC,GACtC,UAAGlB,WAAWa,GAGjBM,EAAcN,GAFdO,EAAeP,IAMnB,yBAA8BhC,GAC5B,UAAIwC,WAAWxC,GACX,UAAImB,WAAWnB,IACjB,EAAAtD,IAAIW,MACF,mBACA,uCAAuC2C,MAG3C,UAAIU,cAAcV,IAQpB,oBAAyByC,EAAuBC,GAC9CpC,EAAsBoC,GACtB,UAAIC,aAAaF,EAAeC,IAGlC,6BACED,EACAC,GAEApC,EAAsBoC,GACjB,UAAGvB,WAAWuB,IACjB,EAAAhG,IAAIW,MACF,uBACA,kEAAkEqF,OAGtE,UAAIC,aAAaF,EAAeC,IAGlC,qBACEE,EACAC,EACAC,GAGA,MAAMC,EAAkB,UAAQtC,MAAMoC,GAAsBrC,IAGtDwC,EAAa,UAAQvH,QAAQmH,EAAcG,GAC5C,UAAG5B,WAAW6B,IACjB,UAAItC,cAAcsC,GAGpB,MAAMC,EAAc,UAAQxH,QAAQmH,EAAcC,GAC9C,UAAG1B,WAAW8B,IAChB,EAAAvG,IAAIW,MACF,eACA,qDAAqDyF,OAIzD,UAAIH,aAAaG,EAAYG,IAG/B,8BACEL,EACAC,EACAC,GAGA,MAAMC,EAAkB,UAAQtC,MAAMoC,GAAsBrC,IAGtDwC,EAAa,UAAQvH,QAAQmH,EAAcG,GAC5C,UAAG5B,WAAW6B,IACjB,UAAItC,cAAcsC,GAGpB,MAAMC,EAAc,UAAQxH,QAAQmH,EAAcC,GAC7C,UAAG1B,WAAW8B,IACjB,EAAAvG,IAAIW,MACF,wBACA,kEAAkEwF,OAItE,UAAIF,aAAaG,EAAYG,K,cC5O/B5J,EAAOD,QAAUyE,QAAQ,O,cCAzBxE,EAAOD,QAAUyE,QAAQ,kB,8ECAzB,aAaa,EAAAqF,oBAAuBC,IAClC,MAAMC,EAAQD,EACXE,OACAD,MAAM,6CACT,IAAKA,EACH,MAAM,IAAIzD,MAAM,qBAAqBwD,MAGvC,MAAO,CACLG,SAAU,CACRC,MAAOC,KAAKC,IAAIC,OAAON,EAAM,IAAK,GAClCO,OAAQD,OAAON,EAAM,IAAM,IAE7BQ,QAAS,CACPL,MAAOC,KAAKC,IAAIC,OAAON,EAAM,IAAK,GAClCO,OAAQD,OAAON,EAAM,IAAM,MAKpB,EAAAS,yBAA2B,IAC3B,EAAAC,qBAAuB,IA+EpC,MAqBMC,EAEF,CACF,IAAK,SACL,IAAK,WACL,IAAK,YACL,IAAK,UACL,KAAM,SAENC,UAAW,WAGb,SAASC,EACPC,GACA,mBAACC,IAED,MAAMC,EAAsB,GAC5B,IAAIC,EAtCkC,CACtCC,iBAAkB,KAClBC,eAAgB,KAChBC,QAAS,KACTC,QAAS,KACTC,gBAAiB,KACjBC,YAAa,KACbC,WAAY,KACZC,SAAU,KACVC,WAAY,KACZC,UAAW,KACXC,SAAU,KACVC,OAAQ,KACRC,MAAO,MA0BHC,EAAe,iBACfC,EAA2B,KAC3BC,EAAoD,KAExD,SAASC,IACHF,IACEC,IACFD,EAAYG,MAAM9H,KAAK4H,GACvBA,EAA0B,MAE5BhB,EAAiBa,MAAOzH,KAAK2H,GAC7BA,EAAc,MAIlB,SAASI,IACPF,IACAlB,EAAO3G,KAAK4G,GACZA,EAzDoC,CACtCC,iBAAkB,KAClBC,eAAgB,KAChBC,QAAS,KACTC,QAAS,KACTC,gBAAiB,KACjBC,YAAa,KACbC,WAAY,KACZC,SAAU,KACVC,WAAY,KACZC,UAAW,KACXC,SAAU,KACVC,OAAQ,KACRC,MAAO,MA+CP,IAAK,IAAI5L,EAAI,EAAGA,EAAI4K,EAAMP,OAAQrK,IAAK,CACrC,MAAMmM,EAAOvB,EAAM5K,GAEnB,GAAc,mBAAV6L,EACF,GAAIM,EAAKtD,WAAW,MAClBgD,EAAQ,gBACRd,EAAiBa,MAAQ,GACzB5L,SACK,GAAImM,EAAKtD,WAAW,eAAgB,CACrCkC,GAAoBA,EAAiBC,kBACvCkB,IAEF,MAAMpC,EAAQqC,EAAKrC,MAAM,qCACzB,IAAKA,EACH,MAAM,IAAIzD,MAAM,kBAAoB8F,GAEtCpB,EAAiBC,iBAAmBlB,EAAM,GAC1CiB,EAAiBE,eAAiBnB,EAAM,QACnC,GAAIqC,EAAKtD,WAAW,aACzBkC,EAAiBG,QAAUiB,EAAKC,MAAM,YAAY/B,QAAQN,YACrD,GAAIoC,EAAKtD,WAAW,aACzBkC,EAAiBI,QAAUgB,EAAKC,MAAM,YAAY/B,QAAQN,YACrD,GAAIoC,EAAKtD,WAAW,sBACzBkC,EAAiBK,gBAAkBe,EAChCC,MAAM,qBAAqB/B,QAC3BN,YACE,GAAIoC,EAAKtD,WAAW,kBACzBkC,EAAiBM,YAAcc,EAC5BC,MAAM,iBAAiB/B,QACvBN,YACE,GAAIoC,EAAKtD,WAAW,gBACzBkC,EAAiBO,WAAaa,EAAKC,MAAM,eAAe/B,QAAQN,YAC3D,GAAIoC,EAAKtD,WAAW,cACzBkC,EAAiBQ,SAAWY,EAAKC,MAAM,aAAa/B,QAAQN,YACvD,GAAIoC,EAAKtD,WAAW,UAAW,CACpC,MAAMiB,EAAQqC,EAAKrC,MAAM,kBACzB,IAAKA,EACH,SAEFiB,EAAiBS,WAAa1B,EAAM,GACpCiB,EAAiBU,UAAY3B,EAAM,QAC1BqC,EAAKtD,WAAW,QACzBkC,EAAiBW,SAAWS,EAAKC,MAAM,SAAS/B,QAAQN,OAC/CoC,EAAKtD,WAAW,UACzBkC,EAAiBY,OAASQ,EAAKC,MAAM,SAAS/B,QAAQN,YAEnD,CACL,GAAIc,GAAsBsB,EAAKtD,WAAW,UAAW,CACnDgD,EAAQ,iBACRK,IACAlM,IACA,SAGF,MAAMqM,EAAW5B,EAAc0B,EAAK,KAAO,KAC3C,OAAQE,GACN,IAAK,SACHL,IArGSnC,EAsGesC,EAAxBL,EAtGsC,CAC9CQ,OAAQ,EAAA1C,oBAAoBC,GAC5BoC,MAAO,IAqGC,MACF,KAAK,KAEHJ,EAAQ,iBACRK,IACAlM,IACA,MACF,IAAK,SACH,IAAKmM,EAAKtD,WAAW,gCACnB,MAAM,IAAIxC,MAAM,sCAAwC8F,GAE1D,IAAKJ,EACH,MAAM,IAAI1F,MACR,0EAGJ0F,EAAwBQ,sBAAuB,EAC/C,MACF,IAAK,YACL,IAAK,WACL,IAAK,UACH,IAAKT,EACH,MAAM,IAAIzF,MACR,+DAIF0F,GACAA,EAAwBS,OAASH,IAEjCP,EAAYG,MAAM9H,KAAK4H,GACvBA,EAA0B,MAEvBA,IACHA,EAA0B,CACxBS,KAAMH,EACNzB,MAAO,GACP2B,sBAAsB,IAG1BR,EAAwBnB,MAAMzG,KAAKgI,EAAKC,MAAM,IAC9C,MACF,QAEE,EAAAK,YAAYJ,KAnJJ,IAACxC,EAwJjBqC,IAEA,IAAK,MAAM,MAACN,KAAUd,EACpB,GAAIc,EACF,IAAK,MAAMc,KAAQd,EACjBe,EAAoBD,GAK1B,OAAO5B,EAGT,SAAgB8B,EAAyBC,GACvC,MAAM/B,EAA0B,GAEhC,IAAK,MAAMgC,KAAQD,EAAO,CACxB,MAAM,iBACJ7B,EAAgB,eAChBC,EAAc,QACdC,EAAO,QACPC,EAAO,gBACPC,EAAe,YACfC,EAAW,WACXC,EAAU,SACVC,EAAQ,WACRC,EAAU,UACVC,EAAS,SACTC,EAAQ,OACRC,EAAM,MACNC,GACEkB,EACEN,EAA8BlB,EAChC,SACAF,EACA,gBACAC,EACA,gBACAO,GAASA,EAAMvB,OAAS,EACxB,QACA,cAEJ,IAAI0C,EAAqC,KACzC,OAAQP,GACN,IAAK,SACH,IAAKlB,IAAeC,EAClB,MAAM,IAAIlF,MAAM,gDAElByE,EAAO3G,KAAK,CACVqI,KAAM,SACNd,SAAUJ,EACVK,OAAQJ,IAEVwB,EAAsBxB,EACtB,MACF,IAAK,gBAAiB,CACpB,MAAM7E,EAAOsE,GAAoBU,EACjC,IAAKhF,EACH,MAAM,IAAIL,MAAM,oDAElByE,EAAO3G,KAAK,CACVqI,KAAM,gBACNE,KAAOd,GAASA,EAAM,IAAO,KAC7BlF,OACAvF,KAAM6L,EAAc5B,GACpB6B,KAAMzB,IAER,MAEF,IAAK,gBAAiB,CACpB,MAAM9E,EAAOuE,GAAkBU,EAC/B,IAAKjF,EACH,MAAM,IAAIL,MAAM,oDAElByE,EAAO3G,KAAK,CACVqI,KAAM,gBACNE,KAAOd,GAASA,EAAM,IAAO,KAC7BlF,OACAvF,KAAM6L,EAAc3B,GACpB4B,KAAMxB,IAER,MAEF,IAAK,QACL,IAAK,cACHsB,EAAsBpB,GAAUV,EAChC,MACF,QACE,EAAAwB,YAAYD,GAGZO,GAAuB7B,GAAWC,GAAWD,IAAYC,GAC3DL,EAAO3G,KAAK,CACVqI,KAAM,cACN9F,KAAMqG,EACN7B,QAAS8B,EAAc9B,GACvBC,QAAS6B,EAAc7B,KAIvB4B,GAAuBnB,GAASA,EAAMvB,QACxCS,EAAO3G,KAAK,CACVqI,KAAM,QACN9F,KAAMqG,EACNnB,QACAJ,aACAC,cAKN,OAAOX,EAGT,SAASkC,EAAc7L,GAErB,MAAM+L,EAAiC,IAApBC,SAAShM,EAAM,GAClC,GACE+L,IAAe,EAAA3C,0BACf2C,IAAe,EAAA1C,qBAEf,MAAM,IAAInE,MAAM,gCAAkClF,GAEpD,OAAO+L,EAyBT,SAAgBP,EAAoBD,GAElC,IAAIU,EAAiB,EACjBC,EAAgB,EACpB,IAAK,MAAM,KAACb,EAAI,MAAE5B,KAAU8B,EAAKT,MAC/B,OAAQO,GACN,IAAK,UACHa,GAAiBzC,EAAMP,OACvB+C,GAAkBxC,EAAMP,OACxB,MACF,IAAK,WACH+C,GAAkBxC,EAAMP,OACxB,MACF,IAAK,YACHgD,GAAiBzC,EAAMP,OACvB,MACF,QACE,EAAAoC,YAAYD,GAIlB,GACEY,IAAmBV,EAAKJ,OAAOtC,SAASK,QACxCgD,IAAkBX,EAAKJ,OAAOhC,QAAQD,OAEtC,MAAM,IAAIhE,MAAM,sCAhKpB,6BAiHA,0BAA+ByG,GAC7B,MAAMlC,EAAQkC,EAAKQ,MAAM,OACO,KAA5B1C,EAAMA,EAAMP,OAAS,IACvBO,EAAM2C,MAER,IACE,OAAOX,EACLjC,EAAgBC,EAAO,CAACC,oBAAoB,KAE9C,MAAO1E,GACP,GACEA,aAAaE,OACC,uCAAdF,EAAElC,QAEF,OAAO2I,EACLjC,EAAgBC,EAAO,CAACC,oBAAoB,KAGhD,MAAM1E,IAIV,yB,8EC7aA,cAEA,sBAA2BqH,GACzB,OAAO,EAAAC,WAAWD,IAGpB,wBAA6BA,GAC3B,OAAO,EAAAE,aAAaF,K,kKCPtB,iBACA,WACA,WACA,QACA,OAgBA,EAAAG,QAAQ,UAAW,UAAW,UAdT,KAWnB,EAAAvK,IAAIC,YAToBF,IAClBA,EAAOkH,OAAS,IAClBuD,QAAQC,UAAY,EACpB1K,EAAOqF,QAAQzE,IACb6J,QAAQxI,OAAO0I,MAAM/J,EAAQ,c,8ECZrC,aAUA,OACA,OACA,OACA,QACA,QA+KA,UA3KqC,CACnCgK,EACAC,EACAC,KAEA,EAAA7K,IAAIiB,KAAK,YAAa,qBAAqB0J,KAC3C,EAAA3K,IAAIiB,KAAK,YAAa,oBAAoB2J,KAC1C,EAAA5K,IAAIiB,KAAK,YAAa,sBAAsB4J,EAAQC,aACpD,EAAA9K,IAAIiB,KAAK,YAAa,0BAA0B4J,EAAQE,iBACxD,EAAA/K,IAAIiB,KAAK,YAAa,0BAA0B4J,EAAQG,iBACxD,EAAAhL,IAAIiB,KAAK,YAAa,0BAA0B4J,EAAQI,iBACxD,EAAAjL,IAAIiB,KAAK,YAAa,0BAA0B4J,EAAQK,iBACxD,EAAAlL,IAAIiB,KAAK,YAAa,yBAAyB4J,EAAQM,gBAEvD,EAAAnL,IAAIiB,KAAK,YAAa,2BAA2B4J,EAAQpJ,kBACzD,EAAAzB,IAAIiB,KACF,YACA,mCAAmC4J,EAAQO,0BAG7C,MAAMC,EAAiB,EAAAnI,YAAYyH,EAAkBE,EAAQC,WAS7D,EAAAQ,cAAcD,GAEVR,EAAQM,eACV,EAAAI,cAAcV,EAAQW,SAAUX,EAAQK,eACxC,EAAAK,cAAcV,EAAQY,UAAWZ,EAAQK,gBAG3C,MAAMnG,EAAgB2G,IACpB,MAAMC,EAAuB,EAAAC,gBAC3BF,EACAf,GAGIkB,EAAoB,EAAAC,qBAAqBJ,GAC/C,GAAIb,EAAQI,cAAczF,SAASqG,GAKjC,YAJA,EAAA7L,IAAIiB,KACF,aACA,iEAwEJ,EAAA8K,mBACEnB,EACAe,EAtEqBK,IACrB,MAAMC,EAAyB1J,IAC7B,EAAA2J,UAAUb,EAAgBM,EAAsB,GAAGpJ,IAAS,KAExD4J,EAAmBxL,IACvB,EAAAX,IAAIW,MAAM,aAAcA,IAEpByL,EAAgCC,IAC/BA,EAGH,EAAArM,IAAIiB,KACF,aACA,wCAAwC0K,KAJ1C,EAAAW,UAAUjB,EAAgBM,EAAsBD,IAQ9Ca,EAAqC7E,IACzC,EAAA1H,IAAIW,MAAM,aAAc,sCAAsC+G,MAY5D,EAAA8E,aAAad,GARf,EAAAe,aACET,EACAN,EACAU,EACAG,GAOF,EAAAG,UACEV,GACA,EACAN,EACAO,EACAE,EACAtB,EAAQpJ,iBAKUuK,IACtB,MAAMC,EAAyB1J,IAC7B,EAAA2J,UAAUb,EAAgBM,EAAsB,GAAGpJ,IAAS,KAExD4J,EAAmBxL,IACvB,EAAAX,IAAIW,MAAM,aAAcA,IAKtB,EAAA6L,aAAad,GAFf,EAAAY,UAAUjB,EAAgBM,EAAsBD,GAKhD,EAAAgB,UACEV,GACA,EACAN,EACAO,EACAE,EACAtB,EAAQpJ,mBAaVuD,EAAqB1B,MAaU,IAAjCuH,EAAQE,cAAc9D,OACxB,EAAArC,kBACE+F,EACA,IACA5F,EACAC,EACA6F,EAAQG,eAGVH,EAAQE,cAAc3F,QAAQtB,IAE1B+G,EAAQG,cAAcxF,SACpB1B,EAAI2B,WAAW,OAAS3B,EAAI4B,OAAO,GAAK5B,GAG1C,EAAA9D,IAAIiB,KACF,aACA,GAAG6C,qEAGL,EAAAc,kBACE+F,EACA7G,EACAiB,EACAC,EACA6F,EAAQG,mB,cCtLlBrO,EAAOD,QAAUyE,QAAQ,Y,kKCAzB,gBACA,OAEA,OAEA,OAuEA,SAASwL,EAAaC,GAEpB,OAAmB,GAAXA,GAA4B,EAvEzB,EAAAhK,eAAiB,CAC5BiK,EACAnK,GACCI,aAED+J,EAAQzH,QAAQ0H,IACd,OAAQA,EAAI1D,MACV,IAAK,gBACH,GAAItG,GACF,IAAK,UAAG2B,WAAWqI,EAAIxJ,MACrB,MAAM,IAAIL,MACR,6CAA+C6J,EAAIxJ,WAKvD,UAAGyJ,WAAWD,EAAIxJ,MAEpB,MACF,IAAK,SACH,GAAIR,GAEF,IAAK,UAAG2B,WAAWqI,EAAIxE,UACrB,MAAM,IAAIrF,MACR,2CAA6C6J,EAAIxE,eAIrD,UAAG0E,SAASF,EAAIxE,SAAUwE,EAAIvE,QAEhC,MACF,IAAK,gBACH,GAAIzF,GACF,GAAI,UAAG2B,WAAWqI,EAAIxJ,MACpB,MAAM,IAAIL,MACR,8CAAgD6J,EAAIxJ,UAInD,CACL,MAAM2J,EAAeH,EAAIxD,KACrBwD,EAAIxD,KAAKT,MAAM,GAAGrB,MAAM0F,KAAK,OAC5BJ,EAAIxD,KAAKT,MAAM,GAAGM,qBAAuB,GAAK,MAC/C,GACJ,UAAGnF,cAAc,EAAAxD,QAAQsM,EAAIxJ,OAC7B,UAAGqB,cAAcmI,EAAIxJ,KAAM2J,EAAc,CAAClP,KAAM+O,EAAI/O,OAEtD,MACF,IAAK,QACH,EAAAiC,IAAIiB,KAAK,eAAgB,kBAoDjC,UACE,MAACuH,EAAK,KAAElF,GACRZ,GACA,OAACI,IAED,MAAMqK,EAAsBzK,GAExBY,EAGJ,IAAI2J,EAAe,GACflP,EAAO,EACP,UAAG0G,WAAW/B,KAChBuK,EAAe,UAAGG,aAAa1K,GAAwBF,WACvDzE,EAAO,UAAGsP,SAAS3K,GAAwB3E,MAG7C,MAAMuP,EAAsBL,EAAa/C,MAAM,MAEzCxC,EAA2B,GAEjC,IAAK,MAAM4B,KAAQd,EAAO,CACxB,IAAI+E,EAAgB,EACpB,OAAa,CACX,MAAMC,EAAgBC,EAAanE,EAAMgE,EAAWC,GACpD,GAAIC,EAAe,CACjB9F,EAAO3G,KAAKyM,GACZ,MAMF,GAHAD,EACEA,EAAgB,GAAqB,EAAjBA,GAAsC,EAAjBA,EAAqB,EAE5DzG,KAAK4G,IAAIH,GAAiB,GAC5B,MAAM,IAAItK,MACR,mBAAmBuF,EAAMmF,QACvBrE,eACY6D,MAMtB,GAAIrK,EACF,OAGF,IAAI8K,EAAa,EAEjB,IAAK,MAAMJ,KAAiB9F,EAC1B,IAAK,MAAMmG,KAAgBL,EACzB,OAAQK,EAAazE,MACnB,IAAK,SACHkE,EAAUQ,OACRD,EAAaE,MAAQH,EACrBC,EAAaG,eACVH,EAAaI,eAElBL,GACEC,EAAaI,cAAchH,OAAS4G,EAAaG,YACnD,MACF,IAAK,MACH,EAAAhO,IAAIkB,QAAQ,eAAgB,kBAC5BoM,EAAUnD,MACV,MACF,IAAK,OACH,EAAAnK,IAAIkB,QAAQ,eAAgB,gBAC5BoM,EAAUvM,KAAK8M,EAAa9E,MAC5B,MACF,QACE,EAAAM,YAAYwE,GAKpB,UAAG7J,cAAc,EAAAxD,QAAQkC,IACzB,UAAGiC,cAAcjC,EAAwB4K,EAAUJ,KAAK,MAAO,CAACnP,SA/H1DmQ,CAAWpB,EAAKpK,EAAwB,CAACI,WACzC,MACF,IAAK,cACH,MAAMqL,EAAc,UAAGd,SAASP,EAAIxJ,MAAMvF,MAEtC4O,EAAaG,EAAI/E,UAAY4E,EAAawB,KACxCxB,EAAaG,EAAI/E,WAAa4E,EAAawB,KAC/CrL,GAEAsL,QAAQpN,KAAK,wCAAwC8L,EAAIxJ,QAE3D,UAAG+K,UAAUvB,EAAIxJ,KAAMwJ,EAAI/E,SAC3B,MACF,QACE,EAAAsB,YAAYyD,OAUpB,MAAMwB,EAAa3P,GAAcA,EAAE4P,QAAQ,OAAQ,IA8HnD,SAASd,EACPnE,EACAgE,EACAC,GAEA,MAAM7F,EAAyB,GAC/B,IAAI8G,EAAelF,EAAKJ,OAAOtC,SAASC,MAAQ,EAAI0G,EAEpD,GAAIiB,EAAe,EACjB,OAAO,KAET,GAAIlB,EAAUrG,OAASuH,EAAelF,EAAKJ,OAAOtC,SAASK,OACzD,OAAO,KAGT,IAAK,MAAMwH,KAAQnF,EAAKT,MACtB,OAAQ4F,EAAKrF,MACX,IAAK,WACL,IAAK,UACH,IAAK,MAAML,KAAQ0F,EAAKjH,MAAO,CAC7B,MAAMkH,EAAepB,EAAUkB,GAC/B,GAlJwBG,EAkJS5F,EAjJlCuF,EAiJoBI,KAjJHJ,EAAUK,GAkJxB,OAAO,KAETH,IAGgB,aAAdC,EAAKrF,OACP1B,EAAO3G,KAAK,CACVqI,KAAM,SACN2E,MAAOS,EAAeC,EAAKjH,MAAMP,OACjC+G,YAAaS,EAAKjH,MAAMP,OACxBgH,cAAe,KAGbQ,EAAKtF,sBACPzB,EAAO3G,KAAK,CACVqI,KAAM,OACNL,KAAM,MAIZ,MACF,IAAK,YACHrB,EAAO3G,KAAK,CACVqI,KAAM,SACN2E,MAAOS,EACPR,YAAa,EACbC,cAAeQ,EAAKjH,QAElBiH,EAAKtF,sBACPzB,EAAO3G,KAAK,CAACqI,KAAM,QAErB,MACF,QACE,EAAAC,YAAYoF,EAAKrF,MApLzB,IAAkCuF,EAwLhC,OAAOjH,I,8EC1QT,aAOA,OAEA,SAASkH,EAAYtF,GACnB,MAAMJ,EAAqB,CACzBtC,SAAU0C,EAAKJ,OAAOhC,QACtBA,QAASoC,EAAKJ,OAAOtC,UAEjBiC,EAAuB,GAE7B,IAAK,MAAM4F,KAAQnF,EAAKT,MACtB,OAAQ4F,EAAKrF,MACX,IAAK,UACHP,EAAM9H,KAAK0N,GACX,MACF,IAAK,WACH5F,EAAM9H,KAAK,CACTqI,KAAM,YACN5B,MAAOiH,EAAKjH,MACZ2B,qBAAsBsF,EAAKtF,uBAE7B,MACF,IAAK,YACHN,EAAM9H,KAAK,CACTqI,KAAM,WACN5B,MAAOiH,EAAKjH,MACZ2B,qBAAsBsF,EAAKtF,uBAE7B,MACF,QACE,EAAAE,YAAYoF,EAAKrF,MAKvB,IAAK,IAAIxM,EAAI,EAAGA,EAAIiM,EAAM5B,OAAS,EAAGrK,IACpC,GAAsB,cAAlBiM,EAAMjM,GAAGwM,MAA8C,aAAtBP,EAAMjM,EAAI,GAAGwM,KAAqB,CACrE,MAAMyF,EAAMhG,EAAMjM,GAClBiM,EAAMjM,GAAKiM,EAAMjM,EAAI,GACrBiM,EAAMjM,EAAI,GAAKiS,EACfjS,GAAK,EAIT,MAAM8K,EAAe,CACnBwB,SACAL,SAKF,OAFA,EAAAU,oBAAoB7B,GAEbA,EAGT,SAASoH,EAAiBL,GACxB,OAAQA,EAAKrF,MACX,IAAK,gBACH,MAAO,CACLA,KAAM,gBACN9F,KAAMmL,EAAKnL,KACXuG,KAAM4E,EAAK5E,KACXP,KAAMmF,EAAKnF,MAAQsF,EAAYH,EAAKnF,MACpCvL,KAAM0Q,EAAK1Q,MAEf,IAAK,gBACH,MAAO,CACLqL,KAAM,gBACN9F,KAAMmL,EAAKnL,KACXgG,KAAMmF,EAAKnF,MAAQsF,EAAYH,EAAKnF,MACpCvL,KAAM0Q,EAAK1Q,KACX8L,KAAM4E,EAAK5E,MAEf,IAAK,SACH,MAAO,CACLT,KAAM,SACNd,SAAUmG,EAAKlG,OACfA,OAAQkG,EAAKnG,UAEjB,IAAK,QACH,MAAO,CACLc,KAAM,QACN9F,KAAMmL,EAAKnL,KACXkF,MAAOiG,EAAKjG,MAAMuG,IAAIH,GACtBxG,WAAYqG,EAAKpG,UACjBA,UAAWoG,EAAKrG,YAEpB,IAAK,cACH,MAAO,CACLgB,KAAM,cACN9F,KAAMmL,EAAKnL,KACXyE,QAAS0G,EAAK3G,QACdA,QAAS2G,EAAK1G,UAKT,EAAAlF,aAAgBN,GACpBA,EAAMwM,IAAID,GAAkBzM,W,8ECtGrC,aAIA,OAEA,sBAA0B,cACxBI,IAQA,IACE,OAAO,EAAAuM,eAAe,EAAA5B,aAAa3K,GAAeD,YAClD,MAAOO,GA4CPyH,QAAQyE,KAAK,GAEf,MAAO,K,cChETtS,EAAOD,QAAUyE,QAAQ,mB,kKCAzB,gBACA,WAEA,OAEA,wBACEC,EACAE,EACAC,EACA4K,GAEA,IACE,MAAM+C,EAAQ,UAAOC,WAAW,OAC1BC,EAAU,UAAIC,iBAAiBjO,GAErCgO,EAAQtN,GAAG,OAAQC,IACjBmN,EAAMI,OAAOvN,KAGfqN,EAAQtN,GAAG,MAAO,KAChB,MAAMyN,EAAcL,EAAMM,OAAO,UAE3BC,EAAQ,UAAON,WAAW,OAC1BO,EAAU,UAAIL,iBAAiB/N,GAErCoO,EAAQ5N,GAAG,OAAQC,IACjB0N,EAAMH,OAAOvN,KAGf2N,EAAQ5N,GAAG,MAAO,KAChB,MAAM6N,EAAcF,EAAMD,OAAO,UAE7BD,IAAgBI,GAClB,EAAA3P,IAAIiB,KACF,eACA,GAAGG,SAAaE,6BAAiCiO,UAAoBI,KAEvEpO,GAAS,KAET,EAAAvB,IAAIiB,KACF,eACA,GAAGG,SAAaE,4BAAgCiO,UAAoBI,KAEtEpO,GAAS,QAIf,MAAOwB,GACPoJ,EAAgB,GAAGpJ,Q,cChDvBpG,EAAOD,QAAUyE,QAAQ,W,8ECAzB,aACA,OAEA,yBAA8BmC,EAAc4H,GAC1C,MACM0E,EAAW,EAAAC,UAAU3E,EADX,CAAC,QAAS,QACyB,CAAC4E,IAAKxM,IACrDsM,EAASjP,OACX,EAAAX,IAAIW,MAAM,gBAAiB,uBAAuBiP,EAASjP,W,8ECP/D,aAQA,OACA,OACA,OAGA,SAASuN,EACPhM,EACAC,EACA0I,EACAtJ,EACAC,GAGA,GADA,EAAAxB,IAAIiB,KAAK,YAAa,YAAYkB,QAAgBD,MAC9C2I,EAAQkF,gBAAiB,CACZ,EAAAC,mBAAmB,CAChCvN,cAAeN,EACfO,uBAAwBR,EACxBG,QAASwI,EAAQxI,WAGjB,EAAArC,IAAIW,MAAM,YAAa,YAAYwB,QAAgBD,kBAErD,EAAA+N,eACE/N,EACAC,EACCuF,IACC,EAAA1H,IAAIiB,KAAK,YAAayG,IAEvBA,IACC,EAAA1H,IAAIW,MAAM,YAAa+G,IAEzBmD,EAAQzI,gBACRyI,EAAQxI,SAiGd,UA5FqC,CACnC6N,EACAC,EACAtF,KAEA,EAAA7K,IAAIiB,KAAK,YAAa,sBAAsBiP,KAC5C,EAAAlQ,IAAIiB,KAAK,YAAa,eAAekP,KACrC,EAAAnQ,IAAIiB,KAAK,YAAa,uBAAuB4J,EAAQuF,cACrD,EAAApQ,IAAIiB,KAAK,YAAa,qBAAqB4J,EAAQkF,mBACnD,EAAA/P,IAAIiB,KAAK,YAAa,oBAAoB4J,EAAQxI,WAClD,EAAArC,IAAIiB,KAAK,YAAa,4BAA4B4J,EAAQzI,mBAE1D,EAAApC,IAAIiB,KAAK,YAAa,0BAA0B4J,EAAQK,iBACxD,EAAAlL,IAAIiB,KAAK,YAAa,yBAAyB4J,EAAQM,gBAEvD,MAAMpG,EAAe,CACnBsL,EACAC,KAEA,MAAMC,EAAwB,EAAA3E,gBAC5ByE,EACAC,GA8CF,EAAAvE,mBACEmE,EACAK,EA7CqBC,IAChB,EAAAhE,aAAa6D,GAchB,EAAAI,kBAAkBJ,EAAkBG,GAbpCtC,EACEsC,EACAH,EACAxF,IAckB6F,IACtB,EAAA1Q,IAAIgB,KACF,YACA,2BAA2B0P,0CAGzB,EAAAlE,aAAa6D,GAEf,EAAAM,SAASN,EAAkBK,GAE3BxC,EACEwC,EACAL,EACAxF,MAmBF7F,EAAoB,CAAC1B,EAAcuB,OAKzCsL,EAAW/K,QAAQ0F,IACjB,MAAM8F,EAAsB,EAAA1N,YAAY2H,EAAQuF,WAAYtF,GAC5D,EAAAlG,kBACEgM,EACA,IACA7L,EACAC,EACA,Q,8ECzHN,aACA,OA8DA,UAxBqC,CACnC6L,EACAR,EACAxF,KAEA,EAAA7K,IAAIiB,KAAK,YAAa,sBAAsB4P,KAC5C,EAAA7Q,IAAIiB,KAAK,YAAa,qBAAqBoP,KAC3C,EAAArQ,IAAIiB,KAAK,YAAa,qBAAqB4J,EAAQkF,mBACnD,EAAA/P,IAAIiB,KAAK,YAAa,oBAAoB4J,EAAQxI,WAClD,EAAArC,IAAIiB,KAAK,YAAa,4BAA4B4J,EAAQzI,mBA5C5D,SACEF,EACAC,EACA0I,EACAtJ,EACAC,GAMA,GAJA,EAAAxB,IAAIiB,KACF,YACA,YAAYkB,QAAgBD,kBAA2B2I,KAErDA,EAAQkF,gBAAiB,CACZ,EAAAC,mBAAmB,CAChCvN,cAAeN,EACfO,uBAAwBR,EACxBG,QAASwI,EAAQxI,WAGjB,EAAArC,IAAIW,MAAM,YAAa,YAAYwB,QAAgBD,kBAErD,EAAA+N,eACE/N,EACAC,EACCuF,IACC,EAAA1H,IAAIiB,KAAK,YAAayG,IAEvBA,IACC,EAAA1H,IAAIW,MAAM,YAAa+G,IAEzBmD,EAAQzI,gBACRyI,EAAQxI,SAgBZ6L,CACE2C,EACAR,EACAxF,K,kKChEJ,iBACA,OAaA,UAAQiG,QAAQ,SAEhB,mBACEC,EACAC,EACAC,EACAC,GA4EA,SAASC,EAAmBtT,EAAeuT,GACzC,OAAOvT,EAAMqM,MAAM,KAGrB,UACGmH,QAAQ,+BACRC,YAAY,kBACZC,OACC,sBACA,iFACA,WAEDA,OACC,2BACA,8KACA,8CAEDA,OACC,0BACA,kCACA,wCAEDA,OACC,kBACA,iIACA,GAEDA,OACC,6BACA,qFACA,GAEDA,OACC,2BACA,6EACAJ,EAxGyB,CAC3B,OACA,YACA,YACA,gBACA,gBACA,YACA,cACA,sBACA,oBACA,OACA,iBACA,UACA,6BACA,aACA,SACA,cACA,OACA,WAEA,SACA,oBAEA,OACA,aACA,QACA,aACA,OACA,UAEA,QACA,OACA,iBACA,iBACA,MAEA,YACA,MAEA,WAEA,yBAEA,WAEA,QAEA,gBAEA,aAEA,mBAEA,QAEA,uBAEA,kBACA,UACA,YACA,UACA,eACA,sBACA,yBACA,gCACA,mBACA,qBAyCCI,OACC,0BACA,4FACAJ,EAjHyB,CAAC,SAoH3BI,OACC,2BACA,2EACAJ,EAzHmC,IA4HpCI,OAAO,sBAAuB,cAC9BC,OACC,CAACC,EAAmBC,EAAkBC,KACpC,EAAA3R,IAAIG,aAAawR,EAAUvR,WAC3B2Q,EAAcU,EAAWC,EAAUC,GAGnCT,MAIN,UACGG,QAAQ,sCACRE,OACC,uBACA,6GACA,oEAEDA,OACC,wBACA,2MAEDA,OACC,4BACA,mNACA,+CAEDA,OAAO,YAAa,wCAAwC,GAC5DA,OACC,0BACA,kCACA,wCAEDA,OACC,kBACA,iIACA,GAEDA,OAAO,sBAAuB,cAC9BC,OACC,CACEI,EACAzB,EACAwB,KAEA,EAAA3R,IAAIG,aAAawR,EAAUvR,WAC3B4Q,EAAcY,EAAYzB,EAAYwB,GACtCT,MAIN,UACGG,QAAQ,8CACRE,OACC,wBACA,2MAEDA,OACC,4BACA,mNACA,+CAEDA,OAAO,YAAa,wCAAwC,GAC5DA,OAAO,sBAAuB,cAC9BC,OACC,CACEK,EACApP,EACAkP,KAEA,EAAA3R,IAAIG,aAAawR,EAAUvR,WAC3B6Q,EAAcY,EAAgBpP,EAAekP,GAC7CT,MAIN,UAAQnN,MAAMyG,QAAQsH,Q,cC9NxBnV,EAAOD,QAAUyE,QAAQ","file":"bundle.js","sourcesContent":[" \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 10);\n","import winston from 'winston';\nimport fs_path from 'path'; // TODO\n\n// Suitable for developments.. may not be when running in the CI/Publish machines.\nconst getLogDirectoryDev = () => {\n  const loggerSourcePath = __dirname;\n  const loggerParentDir = fs_path.resolve(loggerSourcePath, '..');\n  const logDirBase = fs_path.resolve(loggerParentDir, 'logs');\n  return fs_path.resolve(logDirBase, `${Date.now()}`);\n};\n\nconst logDirectory = getLogDirectoryDev();\n\nconst logger = winston.createLogger({\n  level: 'verbose',\n  defaultMeta: {service: 'user-service'},\n  format: winston.format.combine(\n    winston.format.timestamp(),\n    winston.format.json(),\n  ),\n  transports: [\n    new winston.transports.Console({\n      handleExceptions: true,\n      level: 'error',\n    }),\n  ],\n});\n\nfunction setLogFolder(logFolder: string) {\n  // logFolder = fs_path.resolve(logFolder, `${Date.now()}`);\n\n  winston.add(\n    new winston.transports.File({\n      filename: 'error.log',\n      level: 'error',\n      dirname: logFolder,\n    }),\n  );\n  winston.add(\n    new winston.transports.File({\n      filename: `all.log`,\n      dirname: logFolder,\n    }),\n  );\n  winston.exceptions.handle(\n    new winston.transports.File({\n      filename: 'exceptions.log',\n      dirname: logFolder,\n    }),\n  );\n}\n\nfunction info(prefix: string, message: string) {\n  winston.info(`${prefix} - ${message}`);\n}\n\nfunction verbose(prefix: string, message: string) {\n  winston.verbose(`${prefix} - ${message}`);\n}\n\nconst errors: string[] = [];\nfunction error(prefix: string, message: string) {\n  const message2 = `${prefix} - ${message}`;\n  errors.push(message2);\n  winston.error(message2);\n}\n\nfunction warn(prefix: string, message: string) {\n  winston.warn(`${prefix} - ${message}`);\n}\n\nfunction queryErrors(resultCallback: (error: string[]) => void) {\n  // winston.error('Done', () => {\n  //   const options: winston.QueryOptions = {\n  //     // //from: new Date() - 24 * 60 * 60 * 1000,\n  //     until: new Date(),\n  //     limit: 500,\n  //     start: 0,\n  //     order: 'desc',\n  //     fields: ['message', 'level'],\n  //   };\n  //   winston.query(options, (err, results) => {\n  //     if (err) {\n  //       /* TODO: handle me */\n  //       throw err;\n  //     }\n  //     const errors: string[] = [];\n  //     results.file.forEach((element: {level: string; message: string}) => {\n  //       if (element.level === 'error') {\n  //         // tslint:disable-next-line:no-console\n  //         console.log(element.message);\n  //         errors.push(element.message);\n  //       }\n  //     });\n  //     resultCallback(errors);\n  //   });\n  // });\n  resultCallback(errors);\n}\n\nconst log = {queryErrors, setLogFolder, error, warn, info, verbose};\nexport {log};\n","module.exports = require(\"fs-extra\");","module.exports = require(\"path\");","import {spawn} from 'child_process';\n\nimport {log} from './logger';\n\nimport {executeEffects} from './patch/apply';\nimport {reversePatch} from './patch/reverse';\nimport {readPatch} from './patch/read';\n\n// import {InterfaceCLI, getArgs} from './cli';\n// const patchExecutable = getArgs().patchExecutable;\n// const diffExecutable = getArgs().diffExecutable;\n\n// Returns patch between files as string\n// For our use case, the first path is the FB/base repo and the second path is the dirtry fork.\n// For files which doesn't exist in the FB/base repo, the path1IsNew should be set so that we create path for 'new file'\n// Return empty string when files are identical\nexport function diffFiles(\n  path1: string,\n  path1IsNew: boolean /* TODO :: path2IsNew ? */,\n  path2: string,\n  callback: (diff: string) => void,\n  errorcallback: (error: string) => void,\n  diffExecutable: string,\n) {\n  const diffArgs = [path1, path2, '-u' /*-U 3*/];\n  if (path1IsNew) diffArgs.push('--unidirectional-new-file');\n\n  const diff = spawn(diffExecutable, diffArgs);\n\n  diff.stdout.on('data', (data: string) => {\n    callback(data);\n  });\n\n  diff.stderr.on('data', (data: any) => {\n    errorcallback(`${diffExecutable} ${diffArgs} failed with message: ${data}`);\n  });\n\n  diff.on('close', (code: any) => {\n    log.verbose('Patch', `git child process exited with code ${code}`);\n  });\n}\n\nexport function applyPatchTool(\n  targetPath: string,\n  patchPath: string,\n  callback: (result: string) => void,\n  errorcallback: (error: string) => void,\n  patchExecutable: string,\n  reverse: boolean,\n) {\n  const patchArgs = ['-i', patchPath, targetPath, '-s'];\n  if (reverse) {\n    patchArgs.push('-R');\n  }\n\n  const patch = spawn(patchExecutable, patchArgs);\n  log.info(\n    'Patch',\n    'Calling C:\\\\Program Files\\\\Git\\\\usr\\\\bin\\\\patch.exe ' +\n      patchArgs.toString(),\n  );\n\n  patch.on('message', (message: string) => {\n    callback(`Patch message: ${message}`);\n  });\n\n  patch.stdout.on('data', (data: string) => {\n    callback(`Patch output: ${data}`);\n  });\n\n  patch.stderr.on('data', (data: any) => {\n    errorcallback(\n      `${patchExecutable} ${patchArgs} failed with message: ${data}`,\n    );\n  });\n\n  patch.on('close', (code: any) => {\n    log.info('Patch', `patch child process exited with code ${code}`);\n  });\n}\n\nexport function applyPatchEmbedded({\n  patchFilePath,\n  targetFilePathOverride, // Override the target file path in the patch file.\n  reverse,\n}: {\n  patchFilePath: string;\n  targetFilePathOverride: string;\n  reverse: boolean;\n}): boolean {\n  const patch = readPatch({patchFilePath});\n  try {\n    executeEffects(\n      reverse ? reversePatch(patch) : patch,\n      targetFilePathOverride,\n      {\n        dryRun: false,\n      },\n    );\n  } catch (e) {\n    try {\n      executeEffects(\n        reverse ? patch : reversePatch(patch),\n        targetFilePathOverride,\n        {\n          dryRun: true,\n        },\n      );\n    } catch (e) {\n      log.error('patch_utils', `Applying patch failed: ${e}`);\n      return false;\n    }\n  }\n\n  return true;\n}\n","import {log} from '../logger';\nexport function assertNever(x: never): never {\n  log.error(\"assertNever\", \"Unexpected object: \" + x);\n  throw new Error(\"Unexpected object: \" + x)\n}\n","import fs from 'fs';\nimport fse from 'fs-extra';\nimport fs_path from 'path';\nimport {pathToFileURL} from 'url';\nimport {log} from './logger';\n\nexport function getDirectoryFromFilePath(path: string): string {\n  return fs_path.basename(path);\n}\n\nexport function getFileNameExtension(path: string): string {\n  return fs_path.extname(path);\n}\n\nexport function resolvePath(base: string, relative: string): string {\n  return fs_path.resolve(base, relative);\n}\n\nexport function isDirectory(path: string) {\n  try {\n    return fs.lstatSync(path).isDirectory();\n  } catch (e) {\n    log.error('FS:isDirectory', `${path}::${e}`);\n  }\n}\n\nexport function isRegularFile(path: string) {\n  try {\n    return fs.lstatSync(path).isFile();\n  } catch (e) {\n    log.error('FS:isRegularFile', `${path}::${e}`);\n  }\n}\n\nexport function isSymlink(path: string) {\n  try {\n    return fs.lstatSync(path).isSymbolicLink();\n  } catch (e) {\n    log.error('FS:isSymlink', `${path}::${e}`);\n  }\n}\n\nexport function getRelativePath(absPath: string, base: string) {\n  return fs_path.relative(base, absPath);\n}\n\n//\nexport function writeFile(\n  basepath: string,\n  relativefilepath: string,\n  data: string,\n  extension?: string /* Optional extension to be added to the relativefilepath */,\n) {\n  try {\n    // const name2 = 'patch-' + name.replace(/[ &\\/\\\\#,+()$~%.'\":*?<>{}]/g, '-');\n    const name = fs_path.basename(relativefilepath);\n    const relative_dir = fs_path.parse(relativefilepath).dir;\n\n    // Create directory if not exists.\n    const absPath1 = fs_path.resolve(basepath, relative_dir);\n    if (!fs.existsSync(absPath1)) {\n      fse.ensureDirSync(absPath1);\n    }\n\n    const absPath2 = fs_path.resolve(\n      absPath1,\n      extension ? `${name}.${extension}` : name,\n    );\n\n    if (fs.existsSync(absPath2)) {\n      log.error(\n        'FS:writeFile',\n        `Trying to write to file which already exists: ${absPath2}`,\n      );\n    }\n\n    fs.writeFileSync(absPath2, data);\n  } catch (e) {\n    log.error(\n      'FS:writeFile',\n      `File Writing Failed::${basepath}::${relativefilepath}::${e}`,\n    );\n  }\n}\n\n// Note :: Assuming the input path is an absolute path.\n// And callback gets called with absolute path\nexport function traverseDirectory(\n  rootAbsPath: string,\n  relPath: string,\n  callbackFile: (path: string, root: string) => void,\n  callbackDirectory: (path: string, root: string) => void,\n  blackListDirs: string[] = [],\n  recursive: boolean = true,\n) {\n  log.verbose('traverseDirectory', `Entering ${rootAbsPath}\\\\${relPath}`);\n  const path = resolvePath(rootAbsPath, relPath);\n  if (isRegularFile(path)) {\n    callbackFile(path, rootAbsPath);\n  } else if (isDirectory(path)) {\n    const children = fs.readdirSync(path);\n    children.forEach((childpath: string) => {\n      const absChildPath = fs_path.resolve(path, childpath);\n      const relChildPath = relPath + '\\\\' + childpath;\n\n      // Ignore the '.\\' prefix when doing black list comparison\n      if (\n        blackListDirs.includes(\n          relChildPath.startsWith('.\\\\')\n            ? relChildPath.substr(2)\n            : relChildPath,\n        )\n      ) {\n        log.verbose(\n          'traverseDirectory',\n          `Ignoring ${rootAbsPath}\\\\${relChildPath} as it's blacklisted.`,\n        );\n        return;\n      }\n\n      callbackDirectory(absChildPath, rootAbsPath);\n      if (recursive)\n        traverseDirectory(\n          rootAbsPath,\n          relChildPath,\n          callbackFile,\n          callbackDirectory,\n          blackListDirs,\n          recursive,\n        );\n    });\n  } else if (isSymlink(path)) {\n    log.error(\n      'FS:traverseDirectory',\n      `We currently dont support symlinks: ${path}`,\n    );\n  }\n}\n\n// Note :: Lookup a relative path in a give root path\nexport function lookUpRelativePath(\n  path: string,\n  relativePath: string,\n  callbackOnHit: (path: string) => void,\n  callbackOnMiss: (path: string) => void,\n) {\n  const absChildPath = fs_path.resolve(path, relativePath);\n  if (!fs.existsSync(absChildPath)) {\n    callbackOnMiss(absChildPath);\n  } else {\n    callbackOnHit(absChildPath);\n  }\n}\n\nexport function initDirectory(path: string) {\n  fse.removeSync(path);\n  if (fse.existsSync(path)) {\n    log.error(\n      'FS:initDirectory',\n      `Output directory can't be nuked !! (${path})`,\n    );\n  }\n  fse.ensureDirSync(path);\n}\n\nfunction ensureDirOfPathExists(filePath: string) {\n  const dir = fs_path.parse(filePath).dir;\n  fse.ensureDirSync(dir);\n}\n\nexport function copyFile(absSourecPath: string, absDestinationPath: string) {\n  ensureDirOfPathExists(absDestinationPath);\n  fse.copyFileSync(absSourecPath, absDestinationPath);\n}\n\nexport function copyFileOverwrite(\n  absSourecPath: string,\n  absDestinationPath: string,\n) {\n  ensureDirOfPathExists(absDestinationPath);\n  if (!fs.existsSync(absDestinationPath)) {\n    log.error(\n      'FS:copyFileOverwrite',\n      `Trying to overwrite file but the target doesn't already exist (${absDestinationPath})!`,\n    );\n  }\n  fse.copyFileSync(absSourecPath, absDestinationPath);\n}\n\nexport function copyFile2(\n  destBasepath: string,\n  destRelativefilepath: string,\n  sourcePath: string,\n) {\n  // Ensure the directory exists.\n  const destRelativeDir = fs_path.parse(destRelativefilepath).dir;\n\n  // Create directory if not exists.\n  const destAbsDir = fs_path.resolve(destBasepath, destRelativeDir);\n  if (!fs.existsSync(destAbsDir)) {\n    fse.ensureDirSync(destAbsDir);\n  }\n\n  const destAbsPath = fs_path.resolve(destBasepath, destRelativefilepath);\n  if (fs.existsSync(destAbsPath)) {\n    log.error(\n      'FS:copyFile2',\n      `Trying to copy binary file but it already exists (${sourcePath})!`,\n    );\n  }\n\n  fse.copyFileSync(sourcePath, destAbsPath);\n}\n\nexport function copyFile2Overwrite(\n  destBasepath: string,\n  destRelativefilepath: string,\n  sourcePath: string,\n) {\n  // Ensure the directory exists.\n  const destRelativeDir = fs_path.parse(destRelativefilepath).dir;\n\n  // Create directory if not exists.\n  const destAbsDir = fs_path.resolve(destBasepath, destRelativeDir);\n  if (!fs.existsSync(destAbsDir)) {\n    fse.ensureDirSync(destAbsDir);\n  }\n\n  const destAbsPath = fs_path.resolve(destBasepath, destRelativefilepath);\n  if (!fs.existsSync(destAbsPath)) {\n    log.error(\n      'FS:copyFile2Overwrite',\n      `Trying to overwrite file but the target doesn't already exist (${destRelativefilepath})!`,\n    );\n  }\n\n  fse.copyFileSync(sourcePath, destAbsPath);\n}\n","module.exports = require(\"fs\");","module.exports = require(\"child_process\");","import {assertNever} from './assertNever';\n\nexport interface HunkHeader {\n  original: {\n    start: number;\n    length: number;\n  };\n  patched: {\n    start: number;\n    length: number;\n  };\n}\n\nexport const parseHunkHeaderLine = (headerLine: string): HunkHeader => {\n  const match = headerLine\n    .trim()\n    .match(/^@@ -(\\d+)(,(\\d+))? \\+(\\d+)(,(\\d+))? @@.*/);\n  if (!match) {\n    throw new Error(`Bad header line: '${headerLine}'`);\n  }\n\n  return {\n    original: {\n      start: Math.max(Number(match[1]), 1),\n      length: Number(match[3] || 1),\n    },\n    patched: {\n      start: Math.max(Number(match[4]), 1),\n      length: Number(match[6] || 1),\n    },\n  };\n};\n\nexport const NON_EXECUTABLE_FILE_MODE = 0o644;\nexport const EXECUTABLE_FILE_MODE = 0o755;\n\ntype FileMode = typeof NON_EXECUTABLE_FILE_MODE | typeof EXECUTABLE_FILE_MODE;\n\ninterface PatchMutationPart {\n  type: 'context' | 'insertion' | 'deletion';\n  lines: string[];\n  noNewlineAtEndOfFile: boolean;\n}\n\ninterface FileRename {\n  type: 'rename';\n  fromPath: string;\n  toPath: string;\n}\n\ninterface FileModeChange {\n  type: 'mode change';\n  path: string;\n  oldMode: FileMode;\n  newMode: FileMode;\n}\n\nexport interface FilePatch {\n  type: 'patch';\n  path: string;\n  hunks: Hunk[];\n  beforeHash: string | null;\n  afterHash: string | null;\n}\n\ninterface FileDeletion {\n  type: 'file deletion';\n  path: string;\n  mode: FileMode;\n  hunk: Hunk | null;\n  hash: string | null;\n}\n\ninterface FileCreation {\n  type: 'file creation';\n  mode: FileMode;\n  path: string;\n  hunk: Hunk | null;\n  hash: string | null;\n}\n\nexport type PatchFilePart =\n  | FilePatch\n  | FileDeletion\n  | FileCreation\n  | FileRename\n  | FileModeChange;\n\nexport type ParsedPatchFile = PatchFilePart[];\n\ntype State = 'parsing header' | 'parsing hunks';\n\ninterface FileDeets {\n  diffLineFromPath: string | null;\n  diffLineToPath: string | null;\n  oldMode: string | null;\n  newMode: string | null;\n  deletedFileMode: string | null;\n  newFileMode: string | null;\n  renameFrom: string | null;\n  renameTo: string | null;\n  beforeHash: string | null;\n  afterHash: string | null;\n  fromPath: string | null;\n  toPath: string | null;\n  hunks: Hunk[] | null;\n}\n\nexport interface Hunk {\n  header: HunkHeader;\n  parts: PatchMutationPart[];\n}\n\nconst emptyFilePatch = (): FileDeets => ({\n  diffLineFromPath: null,\n  diffLineToPath: null,\n  oldMode: null,\n  newMode: null,\n  deletedFileMode: null,\n  newFileMode: null,\n  renameFrom: null,\n  renameTo: null,\n  beforeHash: null,\n  afterHash: null,\n  fromPath: null,\n  toPath: null,\n  hunks: null,\n});\n\nconst emptyHunk = (headerLine: string): Hunk => ({\n  header: parseHunkHeaderLine(headerLine),\n  parts: [],\n});\n\nconst hunkLinetypes: {\n  [k: string]: PatchMutationPart['type'] | 'pragma' | 'header';\n} = {\n  '@': 'header',\n  '-': 'deletion',\n  '+': 'insertion',\n  ' ': 'context',\n  '\\\\': 'pragma',\n  // Treat blank lines as context\n  undefined: 'context',\n};\n\nfunction parsePatchLines(\n  lines: string[],\n  {supportLegacyDiffs}: {supportLegacyDiffs: boolean},\n): FileDeets[] {\n  const result: FileDeets[] = [];\n  let currentFilePatch: FileDeets = emptyFilePatch();\n  let state: State = 'parsing header';\n  let currentHunk: Hunk | null = null;\n  let currentHunkMutationPart: PatchMutationPart | null = null;\n\n  function commitHunk() {\n    if (currentHunk) {\n      if (currentHunkMutationPart) {\n        currentHunk.parts.push(currentHunkMutationPart);\n        currentHunkMutationPart = null;\n      }\n      currentFilePatch.hunks!.push(currentHunk);\n      currentHunk = null;\n    }\n  }\n\n  function commitFilePatch() {\n    commitHunk();\n    result.push(currentFilePatch);\n    currentFilePatch = emptyFilePatch();\n  }\n\n  for (let i = 0; i < lines.length; i++) {\n    const line = lines[i];\n\n    if (state === 'parsing header') {\n      if (line.startsWith('@@')) {\n        state = 'parsing hunks';\n        currentFilePatch.hunks = [];\n        i--;\n      } else if (line.startsWith('diff --git ')) {\n        if (currentFilePatch && currentFilePatch.diffLineFromPath) {\n          commitFilePatch();\n        }\n        const match = line.match(/^diff --git a\\/(.*?) b\\/(.*?)\\s*$/);\n        if (!match) {\n          throw new Error('Bad diff line: ' + line);\n        }\n        currentFilePatch.diffLineFromPath = match[1];\n        currentFilePatch.diffLineToPath = match[2];\n      } else if (line.startsWith('old mode ')) {\n        currentFilePatch.oldMode = line.slice('old mode '.length).trim();\n      } else if (line.startsWith('new mode ')) {\n        currentFilePatch.newMode = line.slice('new mode '.length).trim();\n      } else if (line.startsWith('deleted file mode ')) {\n        currentFilePatch.deletedFileMode = line\n          .slice('deleted file mode '.length)\n          .trim();\n      } else if (line.startsWith('new file mode ')) {\n        currentFilePatch.newFileMode = line\n          .slice('new file mode '.length)\n          .trim();\n      } else if (line.startsWith('rename from ')) {\n        currentFilePatch.renameFrom = line.slice('rename from '.length).trim();\n      } else if (line.startsWith('rename to ')) {\n        currentFilePatch.renameTo = line.slice('rename to '.length).trim();\n      } else if (line.startsWith('index ')) {\n        const match = line.match(/(\\w+)\\.\\.(\\w+)/);\n        if (!match) {\n          continue;\n        }\n        currentFilePatch.beforeHash = match[1];\n        currentFilePatch.afterHash = match[2];\n      } else if (line.startsWith('--- ')) {\n        currentFilePatch.fromPath = line.slice('--- a/'.length).trim();\n      } else if (line.startsWith('+++ ')) {\n        currentFilePatch.toPath = line.slice('+++ b/'.length).trim();\n      }\n    } else {\n      if (supportLegacyDiffs && line.startsWith('--- a/')) {\n        state = 'parsing header';\n        commitFilePatch();\n        i--;\n        continue;\n      }\n      // parsing hunks\n      const lineType = hunkLinetypes[line[0]] || null;\n      switch (lineType) {\n        case 'header':\n          commitHunk();\n          currentHunk = emptyHunk(line);\n          break;\n        case null:\n          // unrecognized, bail out\n          state = 'parsing header';\n          commitFilePatch();\n          i--;\n          break;\n        case 'pragma':\n          if (!line.startsWith('\\\\ No newline at end of file')) {\n            throw new Error('Unrecognized pragma in patch file: ' + line);\n          }\n          if (!currentHunkMutationPart) {\n            throw new Error(\n              'Bad parser state: No newline at EOF pragma encountered without context',\n            );\n          }\n          currentHunkMutationPart.noNewlineAtEndOfFile = true;\n          break;\n        case 'insertion':\n        case 'deletion':\n        case 'context':\n          if (!currentHunk) {\n            throw new Error(\n              'Bad parser state: Hunk lines encountered before hunk header',\n            );\n          }\n          if (\n            currentHunkMutationPart &&\n            currentHunkMutationPart.type !== lineType\n          ) {\n            currentHunk.parts.push(currentHunkMutationPart);\n            currentHunkMutationPart = null;\n          }\n          if (!currentHunkMutationPart) {\n            currentHunkMutationPart = {\n              type: lineType,\n              lines: [],\n              noNewlineAtEndOfFile: false,\n            };\n          }\n          currentHunkMutationPart.lines.push(line.slice(1));\n          break;\n        default:\n          // exhausitveness check\n          assertNever(lineType);\n      }\n    }\n  }\n\n  commitFilePatch();\n\n  for (const {hunks} of result) {\n    if (hunks) {\n      for (const hunk of hunks) {\n        verifyHunkIntegrity(hunk);\n      }\n    }\n  }\n\n  return result;\n}\n\nexport function interpretParsedPatchFile(files: FileDeets[]): ParsedPatchFile {\n  const result: ParsedPatchFile = [];\n\n  for (const file of files) {\n    const {\n      diffLineFromPath,\n      diffLineToPath,\n      oldMode,\n      newMode,\n      deletedFileMode,\n      newFileMode,\n      renameFrom,\n      renameTo,\n      beforeHash,\n      afterHash,\n      fromPath,\n      toPath,\n      hunks,\n    } = file;\n    const type: PatchFilePart['type'] = renameFrom\n      ? 'rename'\n      : deletedFileMode\n      ? 'file deletion'\n      : newFileMode\n      ? 'file creation'\n      : hunks && hunks.length > 0\n      ? 'patch'\n      : 'mode change';\n\n    let destinationFilePath: string | null = null;\n    switch (type) {\n      case 'rename':\n        if (!renameFrom || !renameTo) {\n          throw new Error('Bad parser state: rename from & to not given');\n        }\n        result.push({\n          type: 'rename',\n          fromPath: renameFrom,\n          toPath: renameTo,\n        });\n        destinationFilePath = renameTo;\n        break;\n      case 'file deletion': {\n        const path = diffLineFromPath || fromPath;\n        if (!path) {\n          throw new Error('Bad parse state: no path given for file deletion');\n        }\n        result.push({\n          type: 'file deletion',\n          hunk: (hunks && hunks[0]) || null,\n          path,\n          mode: parseFileMode(deletedFileMode!),\n          hash: beforeHash,\n        });\n        break;\n      }\n      case 'file creation': {\n        const path = diffLineToPath || toPath;\n        if (!path) {\n          throw new Error('Bad parse state: no path given for file creation');\n        }\n        result.push({\n          type: 'file creation',\n          hunk: (hunks && hunks[0]) || null,\n          path,\n          mode: parseFileMode(newFileMode!),\n          hash: afterHash,\n        });\n        break;\n      }\n      case 'patch':\n      case 'mode change':\n        destinationFilePath = toPath || diffLineToPath;\n        break;\n      default:\n        assertNever(type);\n    }\n\n    if (destinationFilePath && oldMode && newMode && oldMode !== newMode) {\n      result.push({\n        type: 'mode change',\n        path: destinationFilePath,\n        oldMode: parseFileMode(oldMode),\n        newMode: parseFileMode(newMode),\n      });\n    }\n\n    if (destinationFilePath && hunks && hunks.length) {\n      result.push({\n        type: 'patch',\n        path: destinationFilePath,\n        hunks,\n        beforeHash,\n        afterHash,\n      });\n    }\n  }\n\n  return result;\n}\n\nfunction parseFileMode(mode: string): FileMode {\n  // tslint:disable-next-line:no-bitwise\n  const parsedMode = parseInt(mode, 8) & 0o777;\n  if (\n    parsedMode !== NON_EXECUTABLE_FILE_MODE &&\n    parsedMode !== EXECUTABLE_FILE_MODE\n  ) {\n    throw new Error('Unexpected file mode string: ' + mode);\n  }\n  return parsedMode;\n}\n\nexport function parsePatchFile(file: string): ParsedPatchFile {\n  const lines = file.split(/\\n/g);\n  if (lines[lines.length - 1] === '') {\n    lines.pop();\n  }\n  try {\n    return interpretParsedPatchFile(\n      parsePatchLines(lines, {supportLegacyDiffs: false}),\n    );\n  } catch (e) {\n    if (\n      e instanceof Error &&\n      e.message === 'hunk header integrity check failed'\n    ) {\n      return interpretParsedPatchFile(\n        parsePatchLines(lines, {supportLegacyDiffs: true}),\n      );\n    }\n    throw e;\n  }\n}\n\nexport function verifyHunkIntegrity(hunk: Hunk) {\n  // verify hunk integrity\n  let originalLength = 0;\n  let patchedLength = 0;\n  for (const {type, lines} of hunk.parts) {\n    switch (type) {\n      case 'context':\n        patchedLength += lines.length;\n        originalLength += lines.length;\n        break;\n      case 'deletion':\n        originalLength += lines.length;\n        break;\n      case 'insertion':\n        patchedLength += lines.length;\n        break;\n      default:\n        assertNever(type);\n    }\n  }\n\n  if (\n    originalLength !== hunk.header.original.length ||\n    patchedLength !== hunk.header.patched.length\n  ) {\n    throw new Error('hunk header integrity check failed');\n  }\n}\n","import {isTextSync, isBinarySync} from 'istextorbinary';\n\nexport function isFileText(filepath: string) {\n  return isTextSync(filepath);\n}\n\nexport function isFileBinary(filepath: string) {\n  return isBinarySync(filepath);\n}\n","import diffRepos from './diffRepos';\nimport patchRepo from './patchRepo';\nimport patchFile from './patchFile';\nimport {initCli} from './cli';\nimport {log} from './logger';\n\nconst onCompletion = () => {\n  // Check whether there were any errors .. and set the exit code if so.\n  const errorsCallback = (errors: string[]) => {\n    if (errors.length > 0) {\n      process.exitCode = -1;\n      errors.forEach(error => {\n        process.stderr.write(error + '\\n');\n      });\n    }\n  };\n\n  log.queryErrors(errorsCallback);\n};\n\ninitCli(diffRepos, patchRepo, patchFile, onCompletion);\n","import {\n  traverseDirectory,\n  writeFile,\n  getRelativePath,\n  lookUpRelativePath,\n  initDirectory,\n  resolvePath,\n  copyFile2,\n  getFileNameExtension,\n} from './fs_utils';\nimport {diffFiles} from './patch_utils';\nimport {log} from './logger';\nimport {isFileText, isFileBinary} from './file_type_utils';\nimport {compareFiles} from './file_compare';\nimport {cleanRepoSync} from './git_utils';\n\nimport {IDiffCommandOptions, DiffReposFuncType} from './types';\n\nconst diffRepos: DiffReposFuncType = (\n  dirtyRepoAbsPath: string,\n  baseRepoAbsPath: string,\n  options: IDiffCommandOptions,\n) => {\n  log.info('diffRepos', `dirtyRepoAbsPath: ${dirtyRepoAbsPath}`);\n  log.info('diffRepos', `baseRepoAbsPath: ${baseRepoAbsPath}`);\n  log.info('diffRepos', `options.patchName: ${options.patchName}`);\n  log.info('diffRepos', `options.whitelistDirs: ${options.whitelistDirs}`);\n  log.info('diffRepos', `options.blacklistDirs: ${options.blacklistDirs}`);\n  log.info('diffRepos', `options.blacklistExts: ${options.blacklistExts}`);\n  log.info('diffRepos', `options.gitExecutable: ${options.gitExecutable}`);\n  log.info('diffRepos', `options.cleanupRepos: ${options.cleanupRepos}`);\n\n  log.info('diffRepos', `options.diffExecutable: ${options.diffExecutable}`);\n  log.info(\n    'diffRepos',\n    `options.cleanupExistingPatches: ${options.cleanupExistingPatches}`,\n  );\n\n  const patchStorePath = resolvePath(dirtyRepoAbsPath, options.patchName);\n\n  // Where we write the patches ..\n  // const bothPath = resolvePath(patchStorePath, 'both');\n  // const forkOnlyPath = resolvePath(patchStorePath, 'fork-only');\n\n  // Init output directory\n  // initDirectory(bothPath);\n  // initDirectory(forkOnlyPath);\n  initDirectory(patchStorePath);\n\n  if (options.cleanupRepos) {\n    cleanRepoSync(options.baseFork, options.gitExecutable);\n    cleanRepoSync(options.dirtyFork, options.gitExecutable);\n  }\n\n  const callbackFile = (dirtyRepoFileAbsPath: string) => {\n    const forkFileRelativePath = getRelativePath(\n      dirtyRepoFileAbsPath,\n      dirtyRepoAbsPath,\n    );\n\n    const fileNameExtension = getFileNameExtension(dirtyRepoFileAbsPath);\n    if (options.blacklistExts.includes(fileNameExtension)) {\n      log.info(\n        'diffRNFork',\n        `Ignoring {dirtyRepoFileAbsPath} based on file name extension.`,\n      );\n      return;\n    }\n    const callbackOnHit = (fbRepoFileAbsPath: string) => {\n      const callbackOnDiffCreated = (patch: string) => {\n        writeFile(patchStorePath, forkFileRelativePath, `${patch}`, '');\n      };\n      const callbackOnError = (error: string) => {\n        log.error('diffRNFork', error);\n      };\n      const callbackOnBinaryFilesCompare = (same: boolean) => {\n        if (!same) {\n          copyFile2(patchStorePath, forkFileRelativePath, dirtyRepoFileAbsPath);\n        } else {\n          log.info(\n            'diffRNFork',\n            `Skip copying identical binary files: ${forkFileRelativePath}`,\n          );\n        }\n      };\n      const callbackOnBinaryFilesCompareError = (result: string) => {\n        log.error('diffRNFork', `callbackOnBinaryFilesCompareError: ${result}`);\n      };\n\n      const handleBinaryFileInFork = () => {\n        compareFiles(\n          fbRepoFileAbsPath,\n          dirtyRepoFileAbsPath,\n          callbackOnBinaryFilesCompare,\n          callbackOnBinaryFilesCompareError,\n        );\n      };\n      // If it's a binary file we copy it as is to the patches folder.\n      if (isFileBinary(dirtyRepoFileAbsPath)) {\n        handleBinaryFileInFork();\n      } else {\n        diffFiles(\n          fbRepoFileAbsPath,\n          false /* new file*/,\n          dirtyRepoFileAbsPath,\n          callbackOnDiffCreated,\n          callbackOnError,\n          options.diffExecutable,\n        );\n      }\n    };\n\n    const callbackOnMiss = (fbRepoFileAbsPath: string) => {\n      const callbackOnDiffCreated = (patch: string) => {\n        writeFile(patchStorePath, forkFileRelativePath, `${patch}`, '');\n      };\n      const callbackOnError = (error: string) => {\n        log.error('diffRNFork', error);\n      };\n      const handleBinaryFileInFork = () => {\n        copyFile2(patchStorePath, forkFileRelativePath, dirtyRepoFileAbsPath);\n      };\n      if (isFileBinary(dirtyRepoFileAbsPath)) {\n        handleBinaryFileInFork();\n      } else {\n        diffFiles(\n          fbRepoFileAbsPath,\n          true /* new file*/,\n          dirtyRepoFileAbsPath,\n          callbackOnDiffCreated,\n          callbackOnError,\n          options.diffExecutable,\n        );\n      }\n    };\n\n    lookUpRelativePath(\n      baseRepoAbsPath,\n      forkFileRelativePath,\n      callbackOnHit,\n      callbackOnMiss,\n    );\n  };\n\n  const callbackDirectory = (path: string) => {};\n\n  /*\n  Pseudo-code\n  1. Traverse through the fork rep\n  2. For each file look for the same file in the base repo\n  3. If the file is found in the base repo, then create and write the patch file to the patches directory , keeping the same directory hierarchy.\n  4. If the file is not found in the base repo, then also create and write the patch file in the patch directory, keeping the same directory hierarchy.\n  5. If the file is a binary file, we don't try to diff it, instead just copy the binary file to that patch directory.\n\n  Please note that we currently don't traverse the base reporitory, assuming that all the files in the base repository are present in the fork also. Essentially, we expect the patches to be only additions.\n  */\n\n  if (options.whitelistDirs.length === 0) {\n    traverseDirectory(\n      dirtyRepoAbsPath,\n      '.',\n      callbackFile,\n      callbackDirectory,\n      options.blacklistDirs,\n    );\n  } else {\n    options.whitelistDirs.forEach(dir => {\n      if (\n        options.blacklistDirs.includes(\n          dir.startsWith('.\\\\') ? dir.substr(2) : dir,\n        )\n      ) {\n        log.info(\n          'diffRNFork',\n          `${dir} is present in both whitelist as well as blacklist. Ignoring it.`,\n        );\n      } else {\n        traverseDirectory(\n          dirtyRepoAbsPath,\n          dir,\n          callbackFile,\n          callbackDirectory,\n          options.blacklistDirs,\n        );\n      }\n    });\n  }\n};\n\nexport default diffRepos;\n","module.exports = require(\"winston\");","import fs from 'fs-extra';\nimport {dirname} from 'path';\nimport {ParsedPatchFile, FilePatch, Hunk} from './parse';\nimport {assertNever} from './assertNever';\n\nimport {log} from '../logger';\n\nexport const executeEffects = (\n  effects: ParsedPatchFile,\n  targetFilePathOverride: string, // Override the target path in the patch file.\n  {dryRun}: {dryRun: boolean},\n) => {\n  effects.forEach(eff => {\n    switch (eff.type) {\n      case 'file deletion':\n        if (dryRun) {\n          if (!fs.existsSync(eff.path)) {\n            throw new Error(\n              \"Trying to delete file that doesn't exist: \" + eff.path,\n            );\n          }\n        } else {\n          // TODO: integrity checks\n          fs.unlinkSync(eff.path);\n        }\n        break;\n      case 'rename':\n        if (dryRun) {\n          // TODO: see what patch files look like if moving to exising path\n          if (!fs.existsSync(eff.fromPath)) {\n            throw new Error(\n              \"Trying to move file that doesn't exist: \" + eff.fromPath,\n            );\n          }\n        } else {\n          fs.moveSync(eff.fromPath, eff.toPath);\n        }\n        break;\n      case 'file creation':\n        if (dryRun) {\n          if (fs.existsSync(eff.path)) {\n            throw new Error(\n              'Trying to create file that already exists: ' + eff.path,\n            );\n          }\n          // todo: check file contents matches\n        } else {\n          const fileContents = eff.hunk\n            ? eff.hunk.parts[0].lines.join('\\n') +\n              (eff.hunk.parts[0].noNewlineAtEndOfFile ? '' : '\\n')\n            : '';\n          fs.ensureDirSync(dirname(eff.path));\n          fs.writeFileSync(eff.path, fileContents, {mode: eff.mode});\n        }\n        break;\n      case 'patch':\n        log.info('patch\\\\apply', 'Patches found.');\n        applyPatch(eff, targetFilePathOverride, {dryRun});\n        break;\n      case 'mode change':\n        const currentMode = fs.statSync(eff.path).mode;\n        if (\n          ((isExecutable(eff.newMode) && isExecutable(currentMode)) ||\n            (!isExecutable(eff.newMode) && !isExecutable(currentMode))) &&\n          dryRun\n        ) {\n          console.warn(`Mode change is not required for file ${eff.path}`);\n        }\n        fs.chmodSync(eff.path, eff.newMode);\n        break;\n      default:\n        assertNever(eff);\n    }\n  });\n};\n\nfunction isExecutable(fileMode: number) {\n  // tslint:disable-next-line:no-bitwise\n  return (fileMode & 0b001_000_000) > 0;\n}\n\nconst trimRight = (s: string) => s.replace(/\\s+$/, '');\nfunction linesAreEqual(a: string, b: string) {\n  return trimRight(a) === trimRight(b);\n}\n\n/**\n * How does noNewLineAtEndOfFile work?\n *\n * if you remove the newline from a file that had one without editing other bits:\n *\n *    it creates an insertion/removal pair where the insertion has \\ No new line at end of file\n *\n * if you edit a file that didn't have a new line and don't add one:\n *\n *    both insertion and deletion have \\ No new line at end of file\n *\n * if you edit a file that didn't have a new line and add one:\n *\n *    deletion has \\ No new line at end of file\n *    but not insertion\n *\n * if you edit a file that had a new line and leave it in:\n *\n *    neither insetion nor deletion have the annoation\n *\n */\n\nfunction applyPatch(\n  {hunks, path}: FilePatch,\n  targetFilePathOverride: string,\n  {dryRun}: {dryRun: boolean},\n): void {\n  const effectiveTargetPath = targetFilePathOverride\n    ? targetFilePathOverride\n    : path; // Hoping that the ternary opeartor (unlike Nullish coalescing operator) treats empty string as falsy & hence false\n\n  // modifying the file in place\n  let fileContents = '';\n  let mode = 0;\n  if (fs.existsSync(targetFilePathOverride)) {\n    fileContents = fs.readFileSync(targetFilePathOverride).toString();\n    mode = fs.statSync(targetFilePathOverride).mode;\n  }\n\n  const fileLines: string[] = fileContents.split(/\\n/);\n\n  const result: Modificaiton[][] = [];\n\n  for (const hunk of hunks) {\n    let fuzzingOffset = 0;\n    while (true) {\n      const modifications = evaluateHunk(hunk, fileLines, fuzzingOffset);\n      if (modifications) {\n        result.push(modifications);\n        break;\n      }\n\n      fuzzingOffset =\n        fuzzingOffset < 0 ? fuzzingOffset * -1 : fuzzingOffset * -1 - 1;\n\n      if (Math.abs(fuzzingOffset) > 20) {\n        throw new Error(\n          `Cant apply hunk ${hunks.indexOf(\n            hunk,\n          )} for file ${effectiveTargetPath}`,\n        );\n      }\n    }\n  }\n\n  if (dryRun) {\n    return;\n  }\n\n  let diffOffset = 0;\n\n  for (const modifications of result) {\n    for (const modification of modifications) {\n      switch (modification.type) {\n        case 'splice':\n          fileLines.splice(\n            modification.index + diffOffset,\n            modification.numToDelete,\n            ...modification.linesToInsert,\n          );\n          diffOffset +=\n            modification.linesToInsert.length - modification.numToDelete;\n          break;\n        case 'pop':\n          log.verbose('patch\\\\apply', 'Removing lines');\n          fileLines.pop();\n          break;\n        case 'push':\n          log.verbose('patch\\\\apply', 'Adding lines');\n          fileLines.push(modification.line);\n          break;\n        default:\n          assertNever(modification);\n      }\n    }\n  }\n\n  fs.ensureDirSync(dirname(targetFilePathOverride));\n  fs.writeFileSync(targetFilePathOverride, fileLines.join('\\n'), {mode});\n}\n\ninterface Push {\n  type: 'push';\n  line: string;\n}\ninterface Pop {\n  type: 'pop';\n}\ninterface Splice {\n  type: 'splice';\n  index: number;\n  numToDelete: number;\n  linesToInsert: string[];\n}\n\ntype Modificaiton = Push | Pop | Splice;\n\nfunction hunkToString(hunk: Hunk): string {\n  return `@@ -${hunk.header.original.start}, ${hunk.header.original.length} +${hunk.header.patched.start}, ${hunk.header.patched.length} @@`;\n}\n\nfunction evaluateHunk(\n  hunk: Hunk,\n  fileLines: string[],\n  fuzzingOffset: number,\n): Modificaiton[] | null {\n  const result: Modificaiton[] = [];\n  let contextIndex = hunk.header.original.start - 1 + fuzzingOffset;\n  // do bounds checks for index\n  if (contextIndex < 0) {\n    return null;\n  }\n  if (fileLines.length - contextIndex < hunk.header.original.length) {\n    return null;\n  }\n\n  for (const part of hunk.parts) {\n    switch (part.type) {\n      case 'deletion':\n      case 'context':\n        for (const line of part.lines) {\n          const originalLine = fileLines[contextIndex];\n          if (!linesAreEqual(originalLine, line)) {\n            return null;\n          }\n          contextIndex++;\n        }\n\n        if (part.type === 'deletion') {\n          result.push({\n            type: 'splice',\n            index: contextIndex - part.lines.length,\n            numToDelete: part.lines.length,\n            linesToInsert: [],\n          });\n\n          if (part.noNewlineAtEndOfFile) {\n            result.push({\n              type: 'push',\n              line: '',\n            });\n          }\n        }\n        break;\n      case 'insertion':\n        result.push({\n          type: 'splice',\n          index: contextIndex,\n          numToDelete: 0,\n          linesToInsert: part.lines,\n        });\n        if (part.noNewlineAtEndOfFile) {\n          result.push({type: 'pop'});\n        }\n        break;\n      default:\n        assertNever(part.type);\n    }\n  }\n\n  return result;\n}\n","import {\n  ParsedPatchFile,\n  PatchFilePart,\n  Hunk,\n  HunkHeader,\n  verifyHunkIntegrity,\n} from './parse';\nimport {assertNever} from './assertNever';\n\nfunction reverseHunk(hunk: Hunk): Hunk {\n  const header: HunkHeader = {\n    original: hunk.header.patched,\n    patched: hunk.header.original,\n  };\n  const parts: Hunk['parts'] = [];\n\n  for (const part of hunk.parts) {\n    switch (part.type) {\n      case 'context':\n        parts.push(part);\n        break;\n      case 'deletion':\n        parts.push({\n          type: 'insertion',\n          lines: part.lines,\n          noNewlineAtEndOfFile: part.noNewlineAtEndOfFile,\n        });\n        break;\n      case 'insertion':\n        parts.push({\n          type: 'deletion',\n          lines: part.lines,\n          noNewlineAtEndOfFile: part.noNewlineAtEndOfFile,\n        });\n        break;\n      default:\n        assertNever(part.type);\n    }\n  }\n\n  // swap insertions and deletions over so deletions always come first\n  for (let i = 0; i < parts.length - 1; i++) {\n    if (parts[i].type === 'insertion' && parts[i + 1].type === 'deletion') {\n      const tmp = parts[i];\n      parts[i] = parts[i + 1];\n      parts[i + 1] = tmp;\n      i += 1;\n    }\n  }\n\n  const result: Hunk = {\n    header,\n    parts,\n  };\n\n  verifyHunkIntegrity(result);\n\n  return result;\n}\n\nfunction reversePatchPart(part: PatchFilePart): PatchFilePart {\n  switch (part.type) {\n    case 'file creation':\n      return {\n        type: 'file deletion',\n        path: part.path,\n        hash: part.hash,\n        hunk: part.hunk && reverseHunk(part.hunk),\n        mode: part.mode,\n      };\n    case 'file deletion':\n      return {\n        type: 'file creation',\n        path: part.path,\n        hunk: part.hunk && reverseHunk(part.hunk),\n        mode: part.mode,\n        hash: part.hash,\n      };\n    case 'rename':\n      return {\n        type: 'rename',\n        fromPath: part.toPath,\n        toPath: part.fromPath,\n      };\n    case 'patch':\n      return {\n        type: 'patch',\n        path: part.path,\n        hunks: part.hunks.map(reverseHunk),\n        beforeHash: part.afterHash,\n        afterHash: part.beforeHash,\n      };\n    case 'mode change':\n      return {\n        type: 'mode change',\n        path: part.path,\n        newMode: part.oldMode,\n        oldMode: part.newMode,\n      };\n  }\n}\n\nexport const reversePatch = (patch: ParsedPatchFile): ParsedPatchFile => {\n  return patch.map(reversePatchPart).reverse();\n};\n","import chalk from 'chalk';\nimport {readFileSync} from 'fs-extra';\nimport {relative, resolve} from 'path';\nimport {normalize} from 'path';\n// import {PackageDetails} from '../PackageDetails';\nimport {parsePatchFile, PatchFilePart} from './parse';\n\nexport function readPatch({\n  patchFilePath,\n}: // packageDetails,\n// patchDir,\n{\n  patchFilePath: string;\n  // packageDetails: PackageDetails;\n  // patchDir: string;\n}): PatchFilePart[] {\n  try {\n    return parsePatchFile(readFileSync(patchFilePath).toString());\n  } catch (e) {\n    // const fixupSteps: string[] = [];\n    // const relativePatchFilePath = normalize(\n    //   relative(process.cwd(), patchFilePath),\n    // );\n    // const patchBaseDir = relativePatchFilePath.slice(\n    //   0,\n    //   relativePatchFilePath.indexOf(patchDir),\n    // );\n    // if (patchBaseDir) {\n    //   fixupSteps.push(`cd ${patchBaseDir}`);\n    // }\n    // fixupSteps.push(\n    //   `patch -p1 -i ${relativePatchFilePath.slice(\n    //     relativePatchFilePath.indexOf(patchDir),\n    //   )}`,\n    // );\n    // // fixupSteps.push(`npx patch-package ${packageDetails.pathSpecifier}`);\n    // if (patchBaseDir) {\n    //   fixupSteps.push(\n    //     `cd ${relative(resolve(process.cwd(), patchBaseDir), process.cwd())}`,\n    //   );\n    // }\n\n    //     console.error(`\n    // ${chalk.red.bold('**ERROR**')} ${chalk.red(\n    //       `Failed to apply patch for package ${chalk.bold(\n    //         packageDetails.humanReadablePathSpecifier,\n    //       )}`,\n    //     )}\n\n    //   This happened because the patch file ${relativePatchFilePath} could not be parsed.\n\n    //   If you just upgraded patch-package, you can try running:\n\n    //     ${fixupSteps.join('\\n    ')}\n\n    //   Otherwise, try manually creating the patch file again.\n\n    //   If the problem persists, please submit a bug report:\n\n    //     https://github.com/ds300/patch-package/issues/new?title=Patch+file+parse+error&body=%3CPlease+attach+the+patch+file+in+question%3E\n\n    // `);\n    process.exit(1);\n  }\n  return [];\n}\n","module.exports = require(\"istextorbinary\");","import fse from 'fs';\nimport crypto from 'crypto';\n\nimport {log} from './logger';\n\nexport function compareFiles(\n  path1: string,\n  path2: string,\n  callback: (result: boolean) => void,\n  callbackOnError: (result: string) => void,\n) {\n  try {\n    const hash1 = crypto.createHash('md5');\n    const stream1 = fse.createReadStream(path1);\n\n    stream1.on('data', data => {\n      hash1.update(data);\n    });\n\n    stream1.on('end', () => {\n      const hash1Digest = hash1.digest('base64');\n\n      const hash2 = crypto.createHash('md5');\n      const stream2 = fse.createReadStream(path2);\n\n      stream2.on('data', data => {\n        hash2.update(data);\n      });\n\n      stream2.on('end', () => {\n        const hash2Digest = hash2.digest('base64');\n\n        if (hash1Digest === hash2Digest) {\n          log.info(\n            'compareFiles',\n            `${path1} AND ${path2} are identical.  hashes: ${hash1Digest} <==> ${hash2Digest}`,\n          );\n          callback(true);\n        } else {\n          log.info(\n            'compareFiles',\n            `${path1} AND ${path2} are different. hashes: ${hash1Digest} <==> ${hash2Digest}`,\n          );\n          callback(false);\n        }\n      });\n    });\n  } catch (e) {\n    callbackOnError(`${e}`);\n  }\n}\n","module.exports = require(\"crypto\");","import {spawn, spawnSync} from 'child_process';\nimport {log} from './logger';\n\nexport function cleanRepoSync(path: string, gitExecutable: string) {\n  const gitArgs = ['clean', '-fdx'];\n  const gitClean = spawnSync(gitExecutable, gitArgs, {cwd: path});\n  if (gitClean.error) {\n    log.error('cleanRepoSync', `Failed with error : ${gitClean.error}`);\n  }\n}\n","import {\n  traverseDirectory,\n  getRelativePath,\n  lookUpRelativePath,\n  resolvePath,\n  copyFile,\n  copyFileOverwrite,\n} from './fs_utils';\nimport {log} from './logger';\nimport {applyPatchTool, applyPatchEmbedded} from './patch_utils';\nimport {isFileText, isFileBinary} from './file_type_utils';\nimport {IPatchCommandOptions, PatchRepoFuncType} from './types';\n\nfunction applyPatch(\n  targetPath: string,\n  patchPath: string,\n  options: IPatchCommandOptions,\n  callback: (result: string) => void,\n  errorcallback: (error: string) => void,\n) {\n  log.info('PatchRepo', `Applying ${patchPath} on ${targetPath} `);\n  if (options.embeddedPatcher) {\n    const sucess = applyPatchEmbedded({\n      patchFilePath: patchPath,\n      targetFilePathOverride: targetPath,\n      reverse: options.reverse,\n    });\n    if (!sucess)\n      log.error('PatchRepo', `Applying ${patchPath} on ${targetPath} failed.`);\n  } else {\n    applyPatchTool(\n      targetPath,\n      patchPath,\n      (result: string) => {\n        log.info('PatchRepo', result);\n      },\n      (result: string) => {\n        log.error('PatchRepo', result);\n      },\n      options.patchExecutable,\n      options.reverse,\n    );\n  }\n}\n\nconst patchRepo: PatchRepoFuncType = (\n  targetRepoAbsPath: string,\n  patchNames: string[],\n  options: IPatchCommandOptions,\n) => {\n  log.info('patchRepo', `targetRepoAbsPath: ${targetRepoAbsPath}`);\n  log.info('patchRepo', `patchNames: ${patchNames}`);\n  log.info('patchRepo', `options.patchStore: ${options.patchStore}`);\n  log.info('patchRepo', `enbeddedPatcher?: ${options.embeddedPatcher}`);\n  log.info('patchRepo', `options.reverse: ${options.reverse}`);\n  log.info('patchRepo', `options.patchExecutable: ${options.patchExecutable}`);\n\n  log.info('patchRepo', `options.gitExecutable: ${options.gitExecutable}`);\n  log.info('patchRepo', `options.cleanupRepos: ${options.cleanupRepos}`);\n\n  const callbackFile = (\n    patchFileAbsPath: string,\n    patchFileRootAbsPath: string,\n  ) => {\n    const patchFileRelativePath = getRelativePath(\n      patchFileAbsPath,\n      patchFileRootAbsPath,\n    );\n\n    const callbackOnHit = (hitPatchFileAbsPath: string) => {\n      if (!isFileBinary(patchFileAbsPath)) {\n        applyPatch(\n          hitPatchFileAbsPath,\n          patchFileAbsPath,\n          options,\n          (result: string) => {\n            log.info('PatchRepo', result);\n          },\n          (result: string) => {\n            log.error('PatchRepo', result);\n          },\n        );\n      } else {\n        // Overwrite the file.\n        copyFileOverwrite(patchFileAbsPath, hitPatchFileAbsPath);\n      }\n    };\n\n    const callbackOnMiss = (missedPatchFileAbsPath: string) => {\n      log.warn(\n        'PatchRepo',\n        `File path with patches (${missedPatchFileAbsPath}) not found in the target repository.`,\n      );\n\n      if (isFileBinary(patchFileAbsPath)) {\n        // If patch file is binary, we copy anyways.\n        copyFile(patchFileAbsPath, missedPatchFileAbsPath);\n      } else {\n        applyPatch(\n          missedPatchFileAbsPath,\n          patchFileAbsPath,\n          options,\n          (result: string) => {\n            log.info('PatchRepo', result);\n          },\n          (result: string) => {\n            log.error('PatchRepo', result);\n          },\n        );\n      }\n    };\n\n    lookUpRelativePath(\n      targetRepoAbsPath,\n      patchFileRelativePath,\n      callbackOnHit,\n      callbackOnMiss,\n    );\n  };\n\n  const callbackDirectory = (path: string, rootAbsPath: string) => {\n    // tslint:disable-next-line:no-console\n    // console.log('Directory: ' + path);\n  };\n\n  patchNames.forEach(patchName => {\n    const patchNameDirAbsPath = resolvePath(options.patchStore, patchName);\n    traverseDirectory(\n      patchNameDirAbsPath,\n      '.',\n      callbackFile,\n      callbackDirectory,\n      [],\n    );\n  });\n};\n\nexport default patchRepo;\n","import {\n  traverseDirectory,\n  writeFile,\n  getRelativePath,\n  lookUpRelativePath,\n  initDirectory,\n  resolvePath,\n  copyFile,\n  copyFileOverwrite,\n  copyFile2Overwrite,\n} from './fs_utils';\nimport {log} from './logger';\nimport {applyPatchTool, applyPatchEmbedded} from './patch_utils';\nimport {IPatchFileCommandOptions, PatchFileFuncType} from './types';\n\nfunction applyPatch(\n  targetPath: string,\n  patchPath: string,\n  options: IPatchFileCommandOptions,\n  callback: (result: string) => void,\n  errorcallback: (error: string) => void,\n) {\n  log.info(\n    'patchFile',\n    `Applying ${patchPath} on ${targetPath} with options ${options}`,\n  );\n  if (options.embeddedPatcher) {\n    const sucess = applyPatchEmbedded({\n      patchFilePath: patchPath,\n      targetFilePathOverride: targetPath,\n      reverse: options.reverse,\n    });\n    if (!sucess)\n      log.error('patchFile', `Applying ${patchPath} on ${targetPath} failed.`);\n  } else {\n    applyPatchTool(\n      targetPath,\n      patchPath,\n      (result: string) => {\n        log.info('patchFile', result);\n      },\n      (result: string) => {\n        log.error('patchFile', result);\n      },\n      options.patchExecutable,\n      options.reverse,\n    );\n  }\n}\n\nconst patchFile: PatchFileFuncType = (\n  targetFileAbsPath: string,\n  patchFileAbsPath: string,\n  options: IPatchFileCommandOptions,\n) => {\n  log.info('patchFile', `targetFileAbsPath: ${targetFileAbsPath}`);\n  log.info('patchFile', `patchFileAbsPath: ${patchFileAbsPath}`);\n  log.info('patchFile', `enbeddedPatcher?: ${options.embeddedPatcher}`);\n  log.info('patchFile', `options.reverse: ${options.reverse}`);\n  log.info('patchFile', `options.patchExecutable: ${options.patchExecutable}`);\n\n  applyPatch(\n    targetFileAbsPath,\n    patchFileAbsPath,\n    options,\n    (result: string) => {\n      log.info('patchFile', result);\n    },\n    (result: string) => {\n      log.error('patchFile', result);\n    },\n  );\n};\n\nexport default patchFile;\n","import program from 'commander';\nimport {log} from './logger';\nimport fse from 'fs-extra';\n\nimport {\n  DiffReposFuncType,\n  PatchRepoFuncType,\n  PatchFileFuncType,\n  OnCompletionFuncType,\n  IDiffCommandOptions,\n  IPatchCommandOptions,\n  IPatchFileCommandOptions,\n} from './types';\n\nprogram.version('0.0.1');\n\nexport function initCli(\n  diffReposFunc: DiffReposFuncType,\n  patchRepoFunc: PatchRepoFuncType,\n  patchFileFunc: PatchFileFuncType,\n  onCompletionFunc: OnCompletionFuncType,\n) {\n  const defaultWhiteListDirs: string[] = [];\n\n  const defaultBlackListExts = ['.iml'];\n\n  // Places we don't want to look for changes\n  const defaultBlackListDirs = [\n    '.ado',\n    '.appveyor',\n    '.circleci',\n    '.editorconfig',\n    '.eslintignore',\n    '.eslintrc',\n    '.flowconfig',\n    '.flowconfig.android',\n    '.flowconfig.macos',\n    '.git',\n    '.gitattributes',\n    '.github',\n    '.github.flowconfig.android',\n    '.gitignore',\n    '.nvmrc',\n    '.prettierrc',\n    'bots',\n    'Brewfile',\n    //'build.gradle', //'CHANGELOG.json', //'CHANGELOG.md', //'cli.js', //'CODE_OF_CONDUCT.md', //'ContainerShip', //'CONTRIBUTING.md',\n    'danger',\n    'double-conversion',\n    //'ECOSYSTEM.md',\n    'flow',\n    'flow-typed',\n    'Folly',\n    'follybuild',\n    'glog',\n    '.gradle',\n    //'gradle', //'gradlew', //'gradlew.bat', //'IntegrationTests',\n    '.idea',\n    'jest',\n    'jest-preset.js',\n    'jest.config.js',\n    'jsc',\n    //'KeepingRecent.md',\n    'keystores',\n    'lib',\n    //'Libraries', //'LICENSE', //'LICENSE-docs', //'local-cli',\n    'metadata',\n    //'metro.config.js',\n    'office-android-patches',\n    //'package.json',\n    'packages',\n    //'processor',\n    'React',\n    //'react-native.config.js', //'react.gradle',\n    'React.podspec',\n    //'ReactAndroid',\n    'ReactApple',\n    //'ReactCommon', //'README.md', //'Releases.md', //'rn-get-polyfills.js', //'RNTester',\n    'runXcodeTests.sh',\n    //'scripts', //'settings.gradle.kts',\n    'stubs',\n    //'template', //'template.config.js',\n    'third-party-podspecs',\n    //'tools',\n    'v8-docker-build',\n    'website',\n    'yarn.lock',\n    'android',\n    'node_modules',\n    'ReactAndroid\\\\build',\n    'ReactAndroid\\\\packages',\n    'RNTester\\\\android\\\\app\\\\build',\n    'processor\\\\build',\n    'local.properties',\n  ];\n\n  function commaSeparatedList(value: string, dummyPrevious: any) {\n    return value.split(',');\n  }\n\n  program\n    .command('diff <dirtyRepo> <baseRepo>')\n    .description('Diff create ..')\n    .option(\n      '--patch-name <path>',\n      'Name of the patch folder. This new folder will be created under the dirty repo',\n      'patches',\n    )\n    .option(\n      '--diff-executable <path>',\n      'Full path of the diff utility to be used for diffing between files. What we expect is a *x diff utility or compatible one: http://man7.org/linux/man-pages/man1/diff.1.html',\n      'C:\\\\Program Files\\\\Git\\\\usr\\\\bin\\\\diff.exe',\n    )\n    .option(\n      '--git-executable <path>',\n      'Full path of the git executable',\n      'C:\\\\Program Files\\\\Git\\\\bin\\\\git.exe',\n    )\n    .option(\n      '--cleanup-repos',\n      \"Whether to clean up both the dirty and base repos. It will cleanup all non-tracked files. Essentially we run 'git clean -fdx'\",\n      false,\n    )\n    .option(\n      '--cleanup-existing-patches',\n      'Cleanup the existing patches in the patches folder before starting a new diff run',\n      true,\n    )\n    .option(\n      '--blacklist-dirs <paths>',\n      'Paths in dirty repo to be excluded from the patch creation and application',\n      commaSeparatedList,\n      defaultBlackListDirs,\n    )\n    .option(\n      '--blacklist-exts <exts>',\n      'File name extensions in dirty repo to be excluded from the patch creation and application',\n      commaSeparatedList,\n      defaultBlackListExts,\n    )\n    .option(\n      '--whitelist-dirs <paths>',\n      'Paths in dirty repo to be included in the patch creation and application',\n      commaSeparatedList,\n      defaultWhiteListDirs,\n    )\n    .option('--log-folder <path>', 'Log Folder')\n    .action(\n      (dirtyRepo: string, baseRepo: string, cmdObject: IDiffCommandOptions) => {\n        log.setLogFolder(cmdObject.logFolder);\n        diffReposFunc(dirtyRepo, baseRepo, cmdObject);\n\n        // TODO :: This is broken for diffing as we run diffs asynchronously.\n        onCompletionFunc();\n      },\n    );\n\n  program\n    .command('patch <targetRepo> [patchNames...]')\n    .option(\n      '--patch-store <path>',\n      'Full path of the directory where the patches can be found. Each patch is a subdirectory in this directory.',\n      'E:\\\\github\\\\office-android-patches\\\\patches-droid-office-grouped',\n    )\n    .option(\n      '--no-embedded-patcher',\n      \"If true, use the embedded patching code written in Javascript. Currently, this code is taken from the source code the popular package : 'https://github.com/ds300/patch-package'. And adapted. Thanks !\",\n    )\n    .option(\n      '--patch-executable <path>',\n      'Full path of the patch utility to be used for patching. What we expect is a *x patch utility or compatible one: http://man7.org/linux/man-pages/man1/patch.1.html. Used only if embeddedPatcher is set to false.',\n      'C:\\\\Program Files\\\\Git\\\\usr\\\\bin\\\\patch.exe',\n    )\n    .option('--reverse', 'Whether the patch is applied reverse', false)\n    .option(\n      '--git-executable <path>',\n      'Full path of the git executable',\n      'C:\\\\Program Files\\\\Git\\\\bin\\\\git.exe',\n    )\n    .option(\n      '--cleanup-repos',\n      \"Whether to clean up both the dirty and base repos. It will cleanup all non-tracked files. Essentially we run 'git clean -fdx'\",\n      false,\n    )\n    .option('--log-folder <path>', 'Log Folder')\n    .action(\n      (\n        targetRepo: string,\n        patchNames: string[],\n        cmdObject: IPatchCommandOptions,\n      ) => {\n        log.setLogFolder(cmdObject.logFolder);\n        patchRepoFunc(targetRepo, patchNames, cmdObject);\n        onCompletionFunc();\n      },\n    );\n\n  program\n    .command('patchfile <targetFilePath> <patchFilePath>')\n    .option(\n      '--no-embedded-patcher',\n      \"If true, use the embedded patching code written in Javascript. Currently, this code is taken from the source code the popular package : 'https://github.com/ds300/patch-package'. And adapted. Thanks !\",\n    )\n    .option(\n      '--patch-executable <path>',\n      'Full path of the patch utility to be used for patching. What we expect is a *x patch utility or compatible one: http://man7.org/linux/man-pages/man1/patch.1.html. Used only if embeddedPatcher is set to false.',\n      'C:\\\\Program Files\\\\Git\\\\usr\\\\bin\\\\patch.exe',\n    )\n    .option('--reverse', 'Whether the patch is applied reverse', false)\n    .option('--log-folder <path>', 'Log Folder')\n    .action(\n      (\n        targetFilePath: string,\n        patchFilePath: string,\n        cmdObject: IPatchFileCommandOptions,\n      ) => {\n        log.setLogFolder(cmdObject.logFolder);\n        patchFileFunc(targetFilePath, patchFilePath, cmdObject);\n        onCompletionFunc();\n      },\n    );\n\n  program.parse(process.argv);\n}\n","module.exports = require(\"commander\");"],"sourceRoot":""}